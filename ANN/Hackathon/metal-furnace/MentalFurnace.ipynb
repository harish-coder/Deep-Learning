{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Data Preparation Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "##Model Library\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from keras.layers import Dropout,ELU\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from keras_radam import RAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_train  = pd.read_csv(\"Train.csv\")\n",
    "mf_test = pd.read_csv(\"Test.csv\")\n",
    "sb = pd.read_excel('Sample_Submission.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.848564</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>-0.461423</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>1.305455</td>\n",
       "      <td>2.329398</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>-1.080663</td>\n",
       "      <td>0.443257</td>\n",
       "      <td>-0.406121</td>\n",
       "      <td>-0.687687</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>3.727218</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.825098</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>3.032397</td>\n",
       "      <td>-2.442599</td>\n",
       "      <td>1.305455</td>\n",
       "      <td>-0.276144</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>-1.080663</td>\n",
       "      <td>-0.232546</td>\n",
       "      <td>-0.406366</td>\n",
       "      <td>-0.687687</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>-0.232472</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.848564</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>-0.461423</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>1.305455</td>\n",
       "      <td>2.329398</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>0.925358</td>\n",
       "      <td>1.459782</td>\n",
       "      <td>1.221876</td>\n",
       "      <td>1.877777</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>-0.232472</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.511733</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>-0.461423</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>-0.525726</td>\n",
       "      <td>-0.276144</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>0.925358</td>\n",
       "      <td>-0.008030</td>\n",
       "      <td>-0.406366</td>\n",
       "      <td>1.504523</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>-0.232472</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.825098</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>-0.461423</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>-0.525726</td>\n",
       "      <td>-0.276144</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>0.925358</td>\n",
       "      <td>-0.573268</td>\n",
       "      <td>-1.164793</td>\n",
       "      <td>1.877777</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>-0.232472</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0       f1        f2        f3        f4        f5        f6  \\\n",
       "0  1.848564 -0.26425 -0.461423  0.409400  1.305455  2.329398  0.370965   \n",
       "1 -0.825098 -0.26425  3.032397 -2.442599  1.305455 -0.276144  0.370965   \n",
       "2  1.848564 -0.26425 -0.461423  0.409400  1.305455  2.329398  0.370965   \n",
       "3  0.511733 -0.26425 -0.461423  0.409400 -0.525726 -0.276144  0.370965   \n",
       "4 -0.825098 -0.26425 -0.461423  0.409400 -0.525726 -0.276144  0.370965   \n",
       "\n",
       "         f7        f8   f9  ...       f19       f20       f21       f22  \\\n",
       "0  0.090167  0.107958  0.0  ...  0.085505  0.233285 -1.080663  0.443257   \n",
       "1  0.090167  0.107958  0.0  ...  0.085505  0.233285 -1.080663 -0.232546   \n",
       "2  0.090167  0.107958  0.0  ...  0.085505  0.233285  0.925358  1.459782   \n",
       "3  0.090167  0.107958  0.0  ...  0.085505  0.233285  0.925358 -0.008030   \n",
       "4  0.090167  0.107958  0.0  ...  0.085505  0.233285  0.925358 -0.573268   \n",
       "\n",
       "        f23       f24       f25       f26       f27  grade  \n",
       "0 -0.406121 -0.687687  0.271886  3.727218  0.102129      2  \n",
       "1 -0.406366 -0.687687  0.271886 -0.232472  0.102129      4  \n",
       "2  1.221876  1.877777  0.271886 -0.232472  0.102129      2  \n",
       "3 -0.406366  1.504523  0.271886 -0.232472  0.102129      2  \n",
       "4 -1.164793  1.877777  0.271886 -0.232472  0.102129      2  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 3, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_train['grade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.837812</td>\n",
       "      <td>-0.273636</td>\n",
       "      <td>1.276580</td>\n",
       "      <td>0.463262</td>\n",
       "      <td>-0.585142</td>\n",
       "      <td>-0.24287</td>\n",
       "      <td>0.349804</td>\n",
       "      <td>0.12356</td>\n",
       "      <td>0.166795</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197642</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.886135</td>\n",
       "      <td>-0.568935</td>\n",
       "      <td>1.100428</td>\n",
       "      <td>-0.244589</td>\n",
       "      <td>0.229718</td>\n",
       "      <td>-0.217109</td>\n",
       "      <td>0.087039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.078087</td>\n",
       "      <td>-0.273636</td>\n",
       "      <td>-0.496119</td>\n",
       "      <td>0.463262</td>\n",
       "      <td>-2.438092</td>\n",
       "      <td>-0.24287</td>\n",
       "      <td>0.349804</td>\n",
       "      <td>0.12356</td>\n",
       "      <td>0.166795</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.059644</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.886135</td>\n",
       "      <td>0.504299</td>\n",
       "      <td>-0.434268</td>\n",
       "      <td>-0.244040</td>\n",
       "      <td>0.229718</td>\n",
       "      <td>-0.217109</td>\n",
       "      <td>0.087039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.837812</td>\n",
       "      <td>-0.273636</td>\n",
       "      <td>1.276580</td>\n",
       "      <td>0.463262</td>\n",
       "      <td>-0.585142</td>\n",
       "      <td>-0.24287</td>\n",
       "      <td>0.349804</td>\n",
       "      <td>0.12356</td>\n",
       "      <td>0.166795</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197642</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>-1.128496</td>\n",
       "      <td>-0.568935</td>\n",
       "      <td>-0.434268</td>\n",
       "      <td>-0.662763</td>\n",
       "      <td>0.229718</td>\n",
       "      <td>-0.217109</td>\n",
       "      <td>0.087039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.837812</td>\n",
       "      <td>-0.273636</td>\n",
       "      <td>-0.496119</td>\n",
       "      <td>0.463262</td>\n",
       "      <td>1.267808</td>\n",
       "      <td>-0.24287</td>\n",
       "      <td>-2.858743</td>\n",
       "      <td>0.12356</td>\n",
       "      <td>0.166795</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.059644</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>-1.128496</td>\n",
       "      <td>-0.449819</td>\n",
       "      <td>-1.918647</td>\n",
       "      <td>-0.662763</td>\n",
       "      <td>0.229718</td>\n",
       "      <td>-0.217109</td>\n",
       "      <td>0.087039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.837812</td>\n",
       "      <td>-0.273636</td>\n",
       "      <td>-0.496119</td>\n",
       "      <td>0.463262</td>\n",
       "      <td>-0.585142</td>\n",
       "      <td>-0.24287</td>\n",
       "      <td>-2.858743</td>\n",
       "      <td>0.12356</td>\n",
       "      <td>0.166795</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197642</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>-1.128496</td>\n",
       "      <td>-0.568935</td>\n",
       "      <td>-0.434268</td>\n",
       "      <td>-0.662763</td>\n",
       "      <td>0.229718</td>\n",
       "      <td>-0.217109</td>\n",
       "      <td>0.087039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4       f5        f6  \\\n",
       "0 -0.837812 -0.273636  1.276580  0.463262 -0.585142 -0.24287  0.349804   \n",
       "1  2.078087 -0.273636 -0.496119  0.463262 -2.438092 -0.24287  0.349804   \n",
       "2 -0.837812 -0.273636  1.276580  0.463262 -0.585142 -0.24287  0.349804   \n",
       "3 -0.837812 -0.273636 -0.496119  0.463262  1.267808 -0.24287 -2.858743   \n",
       "4 -0.837812 -0.273636 -0.496119  0.463262 -0.585142 -0.24287 -2.858743   \n",
       "\n",
       "        f7        f8       f9  ...       f18      f19      f20       f21  \\\n",
       "0  0.12356  0.166795  0.06143  ...  0.197642  0.06143  0.27735  0.886135   \n",
       "1  0.12356  0.166795  0.06143  ... -5.059644  0.06143  0.27735  0.886135   \n",
       "2  0.12356  0.166795  0.06143  ...  0.197642  0.06143  0.27735 -1.128496   \n",
       "3  0.12356  0.166795  0.06143  ... -5.059644  0.06143  0.27735 -1.128496   \n",
       "4  0.12356  0.166795  0.06143  ...  0.197642  0.06143  0.27735 -1.128496   \n",
       "\n",
       "        f22       f23       f24       f25       f26       f27  \n",
       "0 -0.568935  1.100428 -0.244589  0.229718 -0.217109  0.087039  \n",
       "1  0.504299 -0.434268 -0.244040  0.229718 -0.217109  0.087039  \n",
       "2 -0.568935 -0.434268 -0.662763  0.229718 -0.217109  0.087039  \n",
       "3 -0.449819 -1.918647 -0.662763  0.229718 -0.217109  0.087039  \n",
       "4 -0.568935 -0.434268 -0.662763  0.229718 -0.217109  0.087039  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  0  0  1  0  0\n",
       "1  0  0  0  1  0\n",
       "2  0  0  1  0  0\n",
       "3  0  0  0  1  0\n",
       "4  0  0  1  0  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mf_train.drop(columns=['grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = mf_train['grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = mf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "x_std = std.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_std.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Validating Model\n",
    "- Measures to improve training is applied simultaneously\n",
    "- More training set\n",
    "- Weight Initialization scheme\n",
    "- Available activations (elu)\n",
    "  - Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\n",
    "- Optimizers: adaptvie\n",
    "- Batch Normalization\n",
    "- Dropout (Regularization)\n",
    "- Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network():\n",
    "    classifier = Sequential()\n",
    "\n",
    "     # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = 100, kernel_initializer = 'he_normal', activation = 'elu', input_dim = x_std.shape[1]))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 100, kernel_initializer = 'he_normal', activation = 'elu'))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    \n",
    "     # Adding the third hidden layer\n",
    "    classifier.add(Dense(units = 100, kernel_initializer = 'he_normal', activation = 'elu'))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    \n",
    "     # Adding the four hidden layer\n",
    "    classifier.add(Dense(units = 100, kernel_initializer = 'he_normal', activation = 'elu'))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    \n",
    "\n",
    "    classifier.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    classifier.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])   \n",
    "    ##classifier.compile(RAdam(), loss='categorical_crossentropy', metrics=['acc'])   \n",
    "    return classifier;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 5 models to ensemble\n",
    "model1 = KerasClassifier(build_fn = neural_network, epochs = 100)\n",
    "model2 = KerasClassifier(build_fn = neural_network, epochs = 100)\n",
    "model3 = KerasClassifier(build_fn = neural_network, epochs = 100)\n",
    "model4 = KerasClassifier(build_fn = neural_network, epochs = 100)\n",
    "model5 = KerasClassifier(build_fn = neural_network, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_clf = VotingClassifier(estimators = [('model1', model1), ('model2', model2), ('model3', model3), ('model4', model4), ('model5', model5)], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('model1',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x00000229BFD964C8>),\n",
       "                             ('model2',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x00000229BFDC7608>),\n",
       "                             ('model3',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x00000229BFD96588>),\n",
       "                             ('model4',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x00000229BFD96D48>),\n",
       "                             ('model5',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x00000229BFD966C8>)],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Ensemble Approach, Target value has to be reshape in the form numpy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=mf_train[['grade']].values\n",
    "y_train = y_train.reshape(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 2, 2, 2, 3, 2, 2, 2, 2, 3, 3, 2, 3, 3, 1, 3, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 1,\n",
       "       1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       1, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 4, 0, 2, 1, 1,\n",
       "       2, 2, 1, 4, 2, 2, 2, 3, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 1, 2, 3, 1, 2, 4, 2, 2, 2, 2, 2, 1, 3, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 1, 2, 2, 2, 3, 2, 1, 1, 4, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 1, 2, 3, 2, 2, 1, 1, 1, 2, 3, 4, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 4, 2, 2, 2,\n",
       "       2, 4, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1,\n",
       "       2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 4, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 3, 2, 2, 2, 2, 1, 3, 2, 2, 1, 2, 2, 2, 2, 3, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 1, 1, 2, 2,\n",
       "       2, 2, 2, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 2, 2, 4, 3, 1, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 1, 3, 3, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       3, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       2, 2, 2, 1, 2, 1, 2, 2, 4, 2, 2, 4, 2, 3, 3, 2, 3, 2, 2, 1, 2, 3,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 3, 4, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 4, 1, 2, 2, 2, 2, 2, 1, 2, 4, 3,\n",
       "       2, 2, 1, 2, 2, 2, 3, 2, 2, 1, 2, 3, 2, 2, 0, 2, 2, 2, 4, 2, 3, 2,\n",
       "       2, 3, 4, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2,\n",
       "       3, 4, 2, 0, 3, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 2, 2,\n",
       "       0, 2, 2, 2, 0, 2, 3, 2, 1, 2, 2, 2, 4, 2, 2, 2, 2, 3, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "620/620 [==============================] - 6s 10ms/step - loss: 1.7521 - acc: 0.3306\n",
      "Epoch 2/100\n",
      "620/620 [==============================] - 0s 325us/step - loss: 1.1872 - acc: 0.5581\n",
      "Epoch 3/100\n",
      "620/620 [==============================] - ETA: 0s - loss: 1.0112 - acc: 0.610 - 0s 284us/step - loss: 0.9785 - acc: 0.6323\n",
      "Epoch 4/100\n",
      "620/620 [==============================] - 0s 338us/step - loss: 0.7611 - acc: 0.7468\n",
      "Epoch 5/100\n",
      "620/620 [==============================] - 0s 297us/step - loss: 0.6857 - acc: 0.7935\n",
      "Epoch 6/100\n",
      "620/620 [==============================] - 0s 319us/step - loss: 0.5750 - acc: 0.8081\n",
      "Epoch 7/100\n",
      "620/620 [==============================] - 0s 322us/step - loss: 0.4890 - acc: 0.8371\n",
      "Epoch 8/100\n",
      "620/620 [==============================] - 0s 313us/step - loss: 0.4771 - acc: 0.8484\n",
      "Epoch 9/100\n",
      "620/620 [==============================] - 0s 283us/step - loss: 0.4415 - acc: 0.8516\n",
      "Epoch 10/100\n",
      "620/620 [==============================] - 0s 300us/step - loss: 0.3820 - acc: 0.8758\n",
      "Epoch 11/100\n",
      "620/620 [==============================] - 0s 292us/step - loss: 0.3671 - acc: 0.8823\n",
      "Epoch 12/100\n",
      "620/620 [==============================] - 0s 281us/step - loss: 0.3776 - acc: 0.8742\n",
      "Epoch 13/100\n",
      "620/620 [==============================] - 0s 296us/step - loss: 0.3248 - acc: 0.8919\n",
      "Epoch 14/100\n",
      "620/620 [==============================] - 0s 277us/step - loss: 0.3375 - acc: 0.8871\n",
      "Epoch 15/100\n",
      "620/620 [==============================] - 0s 274us/step - loss: 0.2842 - acc: 0.9000\n",
      "Epoch 16/100\n",
      "620/620 [==============================] - 0s 300us/step - loss: 0.2847 - acc: 0.8968\n",
      "Epoch 17/100\n",
      "620/620 [==============================] - 0s 330us/step - loss: 0.2712 - acc: 0.9016\n",
      "Epoch 18/100\n",
      "620/620 [==============================] - 0s 280us/step - loss: 0.2411 - acc: 0.9032\n",
      "Epoch 19/100\n",
      "620/620 [==============================] - 0s 338us/step - loss: 0.2678 - acc: 0.9081\n",
      "Epoch 20/100\n",
      "620/620 [==============================] - 0s 290us/step - loss: 0.2289 - acc: 0.9097\n",
      "Epoch 21/100\n",
      "620/620 [==============================] - 0s 334us/step - loss: 0.2692 - acc: 0.9000\n",
      "Epoch 22/100\n",
      "620/620 [==============================] - 0s 330us/step - loss: 0.2405 - acc: 0.9081\n",
      "Epoch 23/100\n",
      "620/620 [==============================] - 0s 400us/step - loss: 0.2296 - acc: 0.9048\n",
      "Epoch 24/100\n",
      "620/620 [==============================] - 0s 317us/step - loss: 0.2097 - acc: 0.9145\n",
      "Epoch 25/100\n",
      "620/620 [==============================] - 0s 297us/step - loss: 0.2182 - acc: 0.9226\n",
      "Epoch 26/100\n",
      "620/620 [==============================] - 0s 294us/step - loss: 0.1977 - acc: 0.9210\n",
      "Epoch 27/100\n",
      "620/620 [==============================] - 0s 293us/step - loss: 0.2155 - acc: 0.9177\n",
      "Epoch 28/100\n",
      "620/620 [==============================] - 0s 348us/step - loss: 0.2255 - acc: 0.9000\n",
      "Epoch 29/100\n",
      "620/620 [==============================] - 0s 320us/step - loss: 0.2011 - acc: 0.9242\n",
      "Epoch 30/100\n",
      "620/620 [==============================] - 0s 335us/step - loss: 0.2159 - acc: 0.9177\n",
      "Epoch 31/100\n",
      "620/620 [==============================] - 0s 321us/step - loss: 0.1804 - acc: 0.9274\n",
      "Epoch 32/100\n",
      "620/620 [==============================] - 0s 327us/step - loss: 0.1655 - acc: 0.9419\n",
      "Epoch 33/100\n",
      "620/620 [==============================] - 0s 307us/step - loss: 0.1959 - acc: 0.9274\n",
      "Epoch 34/100\n",
      "620/620 [==============================] - 0s 315us/step - loss: 0.1740 - acc: 0.9274\n",
      "Epoch 35/100\n",
      "620/620 [==============================] - 0s 294us/step - loss: 0.2024 - acc: 0.9129\n",
      "Epoch 36/100\n",
      "620/620 [==============================] - 0s 293us/step - loss: 0.1809 - acc: 0.9274 0s - loss: 0.1775 - acc: 0.929\n",
      "Epoch 37/100\n",
      "620/620 [==============================] - 0s 264us/step - loss: 0.1744 - acc: 0.9355 0s - loss: 0.1684 - acc: 0.94\n",
      "Epoch 38/100\n",
      "620/620 [==============================] - 0s 354us/step - loss: 0.1613 - acc: 0.9290\n",
      "Epoch 39/100\n",
      "620/620 [==============================] - 0s 325us/step - loss: 0.1939 - acc: 0.9290\n",
      "Epoch 40/100\n",
      "620/620 [==============================] - 0s 326us/step - loss: 0.1623 - acc: 0.9339\n",
      "Epoch 41/100\n",
      "620/620 [==============================] - 0s 314us/step - loss: 0.1770 - acc: 0.9403\n",
      "Epoch 42/100\n",
      "620/620 [==============================] - 0s 328us/step - loss: 0.1423 - acc: 0.9516\n",
      "Epoch 43/100\n",
      "620/620 [==============================] - 0s 365us/step - loss: 0.1681 - acc: 0.9339\n",
      "Epoch 44/100\n",
      "620/620 [==============================] - 0s 286us/step - loss: 0.1706 - acc: 0.9274\n",
      "Epoch 45/100\n",
      "620/620 [==============================] - 0s 274us/step - loss: 0.1764 - acc: 0.9290\n",
      "Epoch 46/100\n",
      "620/620 [==============================] - 0s 259us/step - loss: 0.1847 - acc: 0.9290\n",
      "Epoch 47/100\n",
      "620/620 [==============================] - 0s 313us/step - loss: 0.1654 - acc: 0.9339\n",
      "Epoch 48/100\n",
      "620/620 [==============================] - 0s 359us/step - loss: 0.1613 - acc: 0.9355\n",
      "Epoch 49/100\n",
      "620/620 [==============================] - 0s 329us/step - loss: 0.1530 - acc: 0.9468\n",
      "Epoch 50/100\n",
      "620/620 [==============================] - 0s 342us/step - loss: 0.1712 - acc: 0.9339\n",
      "Epoch 51/100\n",
      "620/620 [==============================] - 0s 346us/step - loss: 0.1577 - acc: 0.9387\n",
      "Epoch 52/100\n",
      "620/620 [==============================] - 0s 286us/step - loss: 0.1549 - acc: 0.9403\n",
      "Epoch 53/100\n",
      "620/620 [==============================] - 0s 250us/step - loss: 0.1522 - acc: 0.9452\n",
      "Epoch 54/100\n",
      "620/620 [==============================] - 0s 271us/step - loss: 0.1565 - acc: 0.9468\n",
      "Epoch 55/100\n",
      "620/620 [==============================] - 0s 264us/step - loss: 0.1387 - acc: 0.9419\n",
      "Epoch 56/100\n",
      "620/620 [==============================] - 0s 260us/step - loss: 0.1584 - acc: 0.9419\n",
      "Epoch 57/100\n",
      "620/620 [==============================] - 0s 285us/step - loss: 0.1307 - acc: 0.9548\n",
      "Epoch 58/100\n",
      "620/620 [==============================] - 0s 267us/step - loss: 0.1535 - acc: 0.9403\n",
      "Epoch 59/100\n",
      "620/620 [==============================] - 0s 258us/step - loss: 0.1439 - acc: 0.9435\n",
      "Epoch 60/100\n",
      "620/620 [==============================] - 0s 334us/step - loss: 0.1709 - acc: 0.9355\n",
      "Epoch 61/100\n",
      "620/620 [==============================] - 0s 300us/step - loss: 0.1545 - acc: 0.9484\n",
      "Epoch 62/100\n",
      "620/620 [==============================] - 0s 318us/step - loss: 0.1215 - acc: 0.9565\n",
      "Epoch 63/100\n",
      "620/620 [==============================] - 0s 280us/step - loss: 0.1512 - acc: 0.9387\n",
      "Epoch 64/100\n",
      "620/620 [==============================] - 0s 347us/step - loss: 0.1327 - acc: 0.9500\n",
      "Epoch 65/100\n",
      "620/620 [==============================] - 0s 293us/step - loss: 0.1547 - acc: 0.9435 0s - loss: 0.1533 - acc: 0.944\n",
      "Epoch 66/100\n",
      "620/620 [==============================] - 0s 349us/step - loss: 0.1425 - acc: 0.9468 0s - loss: 0.1207 - acc: 0.9\n",
      "Epoch 67/100\n",
      "620/620 [==============================] - 0s 331us/step - loss: 0.1521 - acc: 0.9387\n",
      "Epoch 68/100\n",
      "620/620 [==============================] - 0s 421us/step - loss: 0.1358 - acc: 0.9532\n",
      "Epoch 69/100\n",
      "620/620 [==============================] - 0s 394us/step - loss: 0.1464 - acc: 0.9419\n",
      "Epoch 70/100\n",
      "620/620 [==============================] - 0s 525us/step - loss: 0.1374 - acc: 0.9548\n",
      "Epoch 71/100\n",
      "620/620 [==============================] - 0s 264us/step - loss: 0.1404 - acc: 0.9452\n",
      "Epoch 72/100\n",
      "620/620 [==============================] - 0s 276us/step - loss: 0.1286 - acc: 0.9484 0s - loss: 0.1059 - acc: 0.952\n",
      "Epoch 73/100\n",
      "620/620 [==============================] - 0s 275us/step - loss: 0.1368 - acc: 0.9468\n",
      "Epoch 74/100\n",
      "620/620 [==============================] - 0s 261us/step - loss: 0.1441 - acc: 0.9435\n",
      "Epoch 75/100\n",
      "620/620 [==============================] - 0s 262us/step - loss: 0.1461 - acc: 0.9306\n",
      "Epoch 76/100\n",
      "620/620 [==============================] - 0s 263us/step - loss: 0.1226 - acc: 0.9484\n",
      "Epoch 77/100\n",
      "620/620 [==============================] - 0s 259us/step - loss: 0.1069 - acc: 0.9629\n",
      "Epoch 78/100\n",
      "620/620 [==============================] - 0s 321us/step - loss: 0.1221 - acc: 0.9597\n",
      "Epoch 79/100\n",
      "620/620 [==============================] - 0s 309us/step - loss: 0.1162 - acc: 0.9581\n",
      "Epoch 80/100\n",
      "620/620 [==============================] - 0s 316us/step - loss: 0.1407 - acc: 0.9452\n",
      "Epoch 81/100\n",
      "620/620 [==============================] - 0s 287us/step - loss: 0.1332 - acc: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "620/620 [==============================] - 0s 317us/step - loss: 0.1235 - acc: 0.9565 0s - loss: 0.1245 - acc: 0.95\n",
      "Epoch 83/100\n",
      "620/620 [==============================] - 0s 290us/step - loss: 0.1321 - acc: 0.9548\n",
      "Epoch 84/100\n",
      "620/620 [==============================] - 0s 357us/step - loss: 0.1144 - acc: 0.9629\n",
      "Epoch 85/100\n",
      "620/620 [==============================] - 0s 281us/step - loss: 0.1388 - acc: 0.9339\n",
      "Epoch 86/100\n",
      "620/620 [==============================] - 0s 312us/step - loss: 0.1445 - acc: 0.9468\n",
      "Epoch 87/100\n",
      "620/620 [==============================] - 0s 292us/step - loss: 0.1140 - acc: 0.9613\n",
      "Epoch 88/100\n",
      "620/620 [==============================] - 0s 315us/step - loss: 0.1110 - acc: 0.9597\n",
      "Epoch 89/100\n",
      "620/620 [==============================] - 0s 275us/step - loss: 0.1278 - acc: 0.9500\n",
      "Epoch 90/100\n",
      "620/620 [==============================] - 0s 307us/step - loss: 0.1089 - acc: 0.9613\n",
      "Epoch 91/100\n",
      "620/620 [==============================] - 0s 266us/step - loss: 0.1168 - acc: 0.9565\n",
      "Epoch 92/100\n",
      "620/620 [==============================] - 0s 286us/step - loss: 0.1261 - acc: 0.9548\n",
      "Epoch 93/100\n",
      "620/620 [==============================] - 0s 282us/step - loss: 0.1414 - acc: 0.9452\n",
      "Epoch 94/100\n",
      "620/620 [==============================] - 0s 267us/step - loss: 0.1204 - acc: 0.9581\n",
      "Epoch 95/100\n",
      "620/620 [==============================] - 0s 248us/step - loss: 0.1144 - acc: 0.9548\n",
      "Epoch 96/100\n",
      "620/620 [==============================] - 0s 313us/step - loss: 0.1094 - acc: 0.9597\n",
      "Epoch 97/100\n",
      "620/620 [==============================] - 0s 290us/step - loss: 0.1121 - acc: 0.9565\n",
      "Epoch 98/100\n",
      "620/620 [==============================] - 0s 306us/step - loss: 0.1125 - acc: 0.9500\n",
      "Epoch 99/100\n",
      "620/620 [==============================] - 0s 267us/step - loss: 0.1098 - acc: 0.9597\n",
      "Epoch 100/100\n",
      "620/620 [==============================] - 0s 301us/step - loss: 0.1133 - acc: 0.9565\n",
      "Epoch 1/100\n",
      "620/620 [==============================] - 6s 9ms/step - loss: 1.8796 - acc: 0.3177\n",
      "Epoch 2/100\n",
      "620/620 [==============================] - 0s 334us/step - loss: 1.2534 - acc: 0.5548\n",
      "Epoch 3/100\n",
      "620/620 [==============================] - 0s 283us/step - loss: 1.0223 - acc: 0.6387\n",
      "Epoch 4/100\n",
      "620/620 [==============================] - 0s 368us/step - loss: 0.8631 - acc: 0.7113\n",
      "Epoch 5/100\n",
      "620/620 [==============================] - 0s 335us/step - loss: 0.7384 - acc: 0.7694\n",
      "Epoch 6/100\n",
      "620/620 [==============================] - 0s 348us/step - loss: 0.6067 - acc: 0.8032\n",
      "Epoch 7/100\n",
      "620/620 [==============================] - 0s 332us/step - loss: 0.5246 - acc: 0.8403\n",
      "Epoch 8/100\n",
      "620/620 [==============================] - 0s 296us/step - loss: 0.5303 - acc: 0.8113\n",
      "Epoch 9/100\n",
      "620/620 [==============================] - 0s 303us/step - loss: 0.4478 - acc: 0.8548\n",
      "Epoch 10/100\n",
      "620/620 [==============================] - 0s 323us/step - loss: 0.4156 - acc: 0.8468\n",
      "Epoch 11/100\n",
      "620/620 [==============================] - 0s 311us/step - loss: 0.4400 - acc: 0.8484\n",
      "Epoch 12/100\n",
      "620/620 [==============================] - 0s 273us/step - loss: 0.3792 - acc: 0.8677\n",
      "Epoch 13/100\n",
      "620/620 [==============================] - 0s 302us/step - loss: 0.3454 - acc: 0.8823\n",
      "Epoch 14/100\n",
      "620/620 [==============================] - 0s 277us/step - loss: 0.3272 - acc: 0.8823\n",
      "Epoch 15/100\n",
      "620/620 [==============================] - 0s 289us/step - loss: 0.3147 - acc: 0.8871\n",
      "Epoch 16/100\n",
      "620/620 [==============================] - 0s 311us/step - loss: 0.3507 - acc: 0.8903\n",
      "Epoch 17/100\n",
      "620/620 [==============================] - 0s 296us/step - loss: 0.2951 - acc: 0.8984\n",
      "Epoch 18/100\n",
      "620/620 [==============================] - 0s 300us/step - loss: 0.2873 - acc: 0.8903\n",
      "Epoch 19/100\n",
      "620/620 [==============================] - 0s 342us/step - loss: 0.2770 - acc: 0.8952\n",
      "Epoch 20/100\n",
      "620/620 [==============================] - 0s 265us/step - loss: 0.2960 - acc: 0.8984\n",
      "Epoch 21/100\n",
      "620/620 [==============================] - ETA: 0s - loss: 0.2698 - acc: 0.901 - 0s 287us/step - loss: 0.2771 - acc: 0.8984\n",
      "Epoch 22/100\n",
      "620/620 [==============================] - 0s 264us/step - loss: 0.2507 - acc: 0.9129\n",
      "Epoch 23/100\n",
      "620/620 [==============================] - 0s 268us/step - loss: 0.2233 - acc: 0.9258\n",
      "Epoch 24/100\n",
      "620/620 [==============================] - 0s 257us/step - loss: 0.2314 - acc: 0.9097\n",
      "Epoch 25/100\n",
      "620/620 [==============================] - 0s 288us/step - loss: 0.2259 - acc: 0.9113\n",
      "Epoch 26/100\n",
      "620/620 [==============================] - 0s 261us/step - loss: 0.2436 - acc: 0.9177 0s - loss: 0.2647 - acc: 0.90\n",
      "Epoch 27/100\n",
      "620/620 [==============================] - 0s 313us/step - loss: 0.1905 - acc: 0.9339\n",
      "Epoch 28/100\n",
      "620/620 [==============================] - 0s 265us/step - loss: 0.2108 - acc: 0.9290\n",
      "Epoch 29/100\n",
      "620/620 [==============================] - 0s 294us/step - loss: 0.2116 - acc: 0.9242\n",
      "Epoch 30/100\n",
      "620/620 [==============================] - 0s 247us/step - loss: 0.2108 - acc: 0.9194\n",
      "Epoch 31/100\n",
      "620/620 [==============================] - 0s 296us/step - loss: 0.2005 - acc: 0.9226\n",
      "Epoch 32/100\n",
      "620/620 [==============================] - 0s 263us/step - loss: 0.2126 - acc: 0.9129\n",
      "Epoch 33/100\n",
      "620/620 [==============================] - 0s 341us/step - loss: 0.1976 - acc: 0.9274\n",
      "Epoch 34/100\n",
      "620/620 [==============================] - 0s 338us/step - loss: 0.1870 - acc: 0.9258\n",
      "Epoch 35/100\n",
      "620/620 [==============================] - 0s 350us/step - loss: 0.1838 - acc: 0.9323\n",
      "Epoch 36/100\n",
      "620/620 [==============================] - 0s 307us/step - loss: 0.2044 - acc: 0.9258\n",
      "Epoch 37/100\n",
      "620/620 [==============================] - 0s 356us/step - loss: 0.1798 - acc: 0.9242\n",
      "Epoch 38/100\n",
      "620/620 [==============================] - 0s 281us/step - loss: 0.1618 - acc: 0.9323\n",
      "Epoch 39/100\n",
      "620/620 [==============================] - 0s 290us/step - loss: 0.1635 - acc: 0.9371\n",
      "Epoch 40/100\n",
      "620/620 [==============================] - 0s 365us/step - loss: 0.2012 - acc: 0.9242\n",
      "Epoch 41/100\n",
      "620/620 [==============================] - 0s 439us/step - loss: 0.1662 - acc: 0.9387\n",
      "Epoch 42/100\n",
      "620/620 [==============================] - 0s 304us/step - loss: 0.2029 - acc: 0.9161\n",
      "Epoch 43/100\n",
      "620/620 [==============================] - 0s 266us/step - loss: 0.1711 - acc: 0.9371\n",
      "Epoch 44/100\n",
      "620/620 [==============================] - 0s 271us/step - loss: 0.1537 - acc: 0.9419\n",
      "Epoch 45/100\n",
      "620/620 [==============================] - 0s 317us/step - loss: 0.1866 - acc: 0.9290\n",
      "Epoch 46/100\n",
      "620/620 [==============================] - 0s 279us/step - loss: 0.1823 - acc: 0.9306\n",
      "Epoch 47/100\n",
      "620/620 [==============================] - 0s 292us/step - loss: 0.1835 - acc: 0.9226\n",
      "Epoch 48/100\n",
      "620/620 [==============================] - 0s 279us/step - loss: 0.1670 - acc: 0.9355\n",
      "Epoch 49/100\n",
      "620/620 [==============================] - 0s 268us/step - loss: 0.1760 - acc: 0.9339\n",
      "Epoch 50/100\n",
      "620/620 [==============================] - 0s 314us/step - loss: 0.1644 - acc: 0.9355\n",
      "Epoch 51/100\n",
      "620/620 [==============================] - 0s 296us/step - loss: 0.1587 - acc: 0.9500\n",
      "Epoch 52/100\n",
      "620/620 [==============================] - 0s 288us/step - loss: 0.1610 - acc: 0.9419\n",
      "Epoch 53/100\n",
      "620/620 [==============================] - 0s 300us/step - loss: 0.1635 - acc: 0.9258\n",
      "Epoch 54/100\n",
      "620/620 [==============================] - 0s 263us/step - loss: 0.1295 - acc: 0.9548\n",
      "Epoch 55/100\n",
      "620/620 [==============================] - 0s 289us/step - loss: 0.1478 - acc: 0.9419\n",
      "Epoch 56/100\n",
      "620/620 [==============================] - 0s 258us/step - loss: 0.1384 - acc: 0.9387\n",
      "Epoch 57/100\n",
      "620/620 [==============================] - 0s 313us/step - loss: 0.1438 - acc: 0.9500\n",
      "Epoch 58/100\n",
      "620/620 [==============================] - 0s 328us/step - loss: 0.1564 - acc: 0.9435\n",
      "Epoch 59/100\n",
      "620/620 [==============================] - 0s 245us/step - loss: 0.1562 - acc: 0.9516\n",
      "Epoch 60/100\n",
      "620/620 [==============================] - 0s 267us/step - loss: 0.1618 - acc: 0.9323\n",
      "Epoch 61/100\n",
      "620/620 [==============================] - 0s 268us/step - loss: 0.1454 - acc: 0.9484\n",
      "Epoch 62/100\n",
      "620/620 [==============================] - 0s 247us/step - loss: 0.1284 - acc: 0.9500\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/620 [==============================] - 0s 280us/step - loss: 0.1276 - acc: 0.9516\n",
      "Epoch 64/100\n",
      "620/620 [==============================] - 0s 274us/step - loss: 0.1488 - acc: 0.9500\n",
      "Epoch 65/100\n",
      "620/620 [==============================] - 0s 276us/step - loss: 0.1387 - acc: 0.9435\n",
      "Epoch 66/100\n",
      "620/620 [==============================] - 0s 330us/step - loss: 0.1516 - acc: 0.9274\n",
      "Epoch 67/100\n",
      "620/620 [==============================] - 0s 337us/step - loss: 0.1482 - acc: 0.9419\n",
      "Epoch 68/100\n",
      "620/620 [==============================] - 0s 280us/step - loss: 0.1338 - acc: 0.9532\n",
      "Epoch 69/100\n",
      "620/620 [==============================] - 0s 298us/step - loss: 0.1335 - acc: 0.9500\n",
      "Epoch 70/100\n",
      "620/620 [==============================] - 0s 266us/step - loss: 0.1284 - acc: 0.9516\n",
      "Epoch 71/100\n",
      "620/620 [==============================] - 0s 288us/step - loss: 0.1540 - acc: 0.9435\n",
      "Epoch 72/100\n",
      "620/620 [==============================] - 0s 271us/step - loss: 0.1375 - acc: 0.9419\n",
      "Epoch 73/100\n",
      "620/620 [==============================] - 0s 291us/step - loss: 0.1340 - acc: 0.9532\n",
      "Epoch 74/100\n",
      "620/620 [==============================] - 0s 268us/step - loss: 0.1441 - acc: 0.9339\n",
      "Epoch 75/100\n",
      "620/620 [==============================] - 0s 368us/step - loss: 0.1200 - acc: 0.9435\n",
      "Epoch 76/100\n",
      "620/620 [==============================] - 0s 268us/step - loss: 0.1285 - acc: 0.9548\n",
      "Epoch 77/100\n",
      "620/620 [==============================] - 0s 311us/step - loss: 0.1203 - acc: 0.9500\n",
      "Epoch 78/100\n",
      "620/620 [==============================] - 0s 247us/step - loss: 0.1364 - acc: 0.9516\n",
      "Epoch 79/100\n",
      "620/620 [==============================] - 0s 269us/step - loss: 0.1157 - acc: 0.9581\n",
      "Epoch 80/100\n",
      "620/620 [==============================] - 0s 291us/step - loss: 0.1339 - acc: 0.9419\n",
      "Epoch 81/100\n",
      "620/620 [==============================] - 0s 329us/step - loss: 0.1447 - acc: 0.9419\n",
      "Epoch 82/100\n",
      "620/620 [==============================] - 0s 326us/step - loss: 0.1193 - acc: 0.9516\n",
      "Epoch 83/100\n",
      "620/620 [==============================] - 0s 307us/step - loss: 0.1604 - acc: 0.9323\n",
      "Epoch 84/100\n",
      "620/620 [==============================] - 0s 296us/step - loss: 0.1351 - acc: 0.9419\n",
      "Epoch 85/100\n",
      "620/620 [==============================] - 0s 324us/step - loss: 0.1167 - acc: 0.9516\n",
      "Epoch 86/100\n",
      "620/620 [==============================] - 0s 271us/step - loss: 0.1052 - acc: 0.9645\n",
      "Epoch 87/100\n",
      "620/620 [==============================] - 0s 303us/step - loss: 0.1274 - acc: 0.9532\n",
      "Epoch 88/100\n",
      "620/620 [==============================] - 0s 274us/step - loss: 0.1306 - acc: 0.9500\n",
      "Epoch 89/100\n",
      "620/620 [==============================] - 0s 296us/step - loss: 0.1262 - acc: 0.9548\n",
      "Epoch 90/100\n",
      "620/620 [==============================] - 0s 278us/step - loss: 0.1162 - acc: 0.9548\n",
      "Epoch 91/100\n",
      "620/620 [==============================] - 0s 295us/step - loss: 0.1209 - acc: 0.9500\n",
      "Epoch 92/100\n",
      "620/620 [==============================] - 0s 234us/step - loss: 0.1196 - acc: 0.9565\n",
      "Epoch 93/100\n",
      "620/620 [==============================] - 0s 274us/step - loss: 0.1182 - acc: 0.9565\n",
      "Epoch 94/100\n",
      "620/620 [==============================] - 0s 284us/step - loss: 0.1383 - acc: 0.9452\n",
      "Epoch 95/100\n",
      "620/620 [==============================] - 0s 310us/step - loss: 0.0943 - acc: 0.9645 0s - loss: 0.0968 - acc: 0.9\n",
      "Epoch 96/100\n",
      "620/620 [==============================] - 0s 290us/step - loss: 0.1079 - acc: 0.9565\n",
      "Epoch 97/100\n",
      "620/620 [==============================] - 0s 304us/step - loss: 0.1165 - acc: 0.9548\n",
      "Epoch 98/100\n",
      "620/620 [==============================] - 0s 258us/step - loss: 0.1197 - acc: 0.9532\n",
      "Epoch 99/100\n",
      "620/620 [==============================] - 0s 304us/step - loss: 0.0968 - acc: 0.9629\n",
      "Epoch 100/100\n",
      "620/620 [==============================] - 0s 277us/step - loss: 0.1013 - acc: 0.9581\n",
      "Epoch 1/100\n",
      "620/620 [==============================] - 4s 7ms/step - loss: 1.6856 - acc: 0.3274\n",
      "Epoch 2/100\n",
      "620/620 [==============================] - 0s 276us/step - loss: 1.1572 - acc: 0.5952\n",
      "Epoch 3/100\n",
      "620/620 [==============================] - 0s 295us/step - loss: 0.9311 - acc: 0.6952 0s - loss: 0.9243 - acc: 0.699\n",
      "Epoch 4/100\n",
      "620/620 [==============================] - 0s 279us/step - loss: 0.7835 - acc: 0.7532\n",
      "Epoch 5/100\n",
      "620/620 [==============================] - 0s 309us/step - loss: 0.6604 - acc: 0.7919\n",
      "Epoch 6/100\n",
      "620/620 [==============================] - 0s 342us/step - loss: 0.6062 - acc: 0.8210\n",
      "Epoch 7/100\n",
      "620/620 [==============================] - 0s 300us/step - loss: 0.5080 - acc: 0.8435\n",
      "Epoch 8/100\n",
      "620/620 [==============================] - 0s 357us/step - loss: 0.4366 - acc: 0.8694\n",
      "Epoch 9/100\n",
      "620/620 [==============================] - 0s 305us/step - loss: 0.4543 - acc: 0.8597\n",
      "Epoch 10/100\n",
      "620/620 [==============================] - 0s 320us/step - loss: 0.4205 - acc: 0.8516\n",
      "Epoch 11/100\n",
      "620/620 [==============================] - 0s 322us/step - loss: 0.3530 - acc: 0.8887\n",
      "Epoch 12/100\n",
      "620/620 [==============================] - 0s 301us/step - loss: 0.3621 - acc: 0.8774\n",
      "Epoch 13/100\n",
      "620/620 [==============================] - 0s 311us/step - loss: 0.3414 - acc: 0.8774\n",
      "Epoch 14/100\n",
      "620/620 [==============================] - 0s 302us/step - loss: 0.2906 - acc: 0.9129\n",
      "Epoch 15/100\n",
      "620/620 [==============================] - 0s 286us/step - loss: 0.3229 - acc: 0.8887\n",
      "Epoch 16/100\n",
      "620/620 [==============================] - 0s 284us/step - loss: 0.2778 - acc: 0.8952\n",
      "Epoch 17/100\n",
      "620/620 [==============================] - 0s 291us/step - loss: 0.2871 - acc: 0.8903\n",
      "Epoch 18/100\n",
      "620/620 [==============================] - 0s 292us/step - loss: 0.2705 - acc: 0.8984\n",
      "Epoch 19/100\n",
      "620/620 [==============================] - 0s 310us/step - loss: 0.2739 - acc: 0.8919\n",
      "Epoch 20/100\n",
      "620/620 [==============================] - 0s 286us/step - loss: 0.2487 - acc: 0.9097\n",
      "Epoch 21/100\n",
      "620/620 [==============================] - 0s 314us/step - loss: 0.2579 - acc: 0.8984\n",
      "Epoch 22/100\n",
      "620/620 [==============================] - 0s 284us/step - loss: 0.2513 - acc: 0.9113\n",
      "Epoch 23/100\n",
      "620/620 [==============================] - 0s 308us/step - loss: 0.2375 - acc: 0.9161\n",
      "Epoch 24/100\n",
      "620/620 [==============================] - 0s 286us/step - loss: 0.2340 - acc: 0.9161\n",
      "Epoch 25/100\n",
      "620/620 [==============================] - 0s 306us/step - loss: 0.2199 - acc: 0.9161\n",
      "Epoch 26/100\n",
      "620/620 [==============================] - 0s 267us/step - loss: 0.2258 - acc: 0.9210\n",
      "Epoch 27/100\n",
      "620/620 [==============================] - 0s 348us/step - loss: 0.2041 - acc: 0.9210\n",
      "Epoch 28/100\n",
      "620/620 [==============================] - 0s 327us/step - loss: 0.2058 - acc: 0.9177\n",
      "Epoch 29/100\n",
      "620/620 [==============================] - 0s 346us/step - loss: 0.1843 - acc: 0.9371\n",
      "Epoch 30/100\n",
      "620/620 [==============================] - 0s 330us/step - loss: 0.1675 - acc: 0.9355\n",
      "Epoch 31/100\n",
      "620/620 [==============================] - 0s 292us/step - loss: 0.2042 - acc: 0.9210\n",
      "Epoch 32/100\n",
      "620/620 [==============================] - 0s 285us/step - loss: 0.2075 - acc: 0.9113\n",
      "Epoch 33/100\n",
      "620/620 [==============================] - 0s 272us/step - loss: 0.2017 - acc: 0.9113\n",
      "Epoch 34/100\n",
      "620/620 [==============================] - 0s 291us/step - loss: 0.1794 - acc: 0.9355\n",
      "Epoch 35/100\n",
      "620/620 [==============================] - 0s 280us/step - loss: 0.1752 - acc: 0.9371\n",
      "Epoch 36/100\n",
      "620/620 [==============================] - 0s 291us/step - loss: 0.1806 - acc: 0.9355\n",
      "Epoch 37/100\n",
      "620/620 [==============================] - 0s 283us/step - loss: 0.1380 - acc: 0.9548\n",
      "Epoch 38/100\n",
      "620/620 [==============================] - 0s 276us/step - loss: 0.1894 - acc: 0.9323\n",
      "Epoch 39/100\n",
      "620/620 [==============================] - 0s 291us/step - loss: 0.1797 - acc: 0.9242\n",
      "Epoch 40/100\n",
      "620/620 [==============================] - 0s 260us/step - loss: 0.1446 - acc: 0.9548\n",
      "Epoch 41/100\n",
      "620/620 [==============================] - 0s 281us/step - loss: 0.1765 - acc: 0.9355\n",
      "Epoch 42/100\n",
      "620/620 [==============================] - 0s 266us/step - loss: 0.1572 - acc: 0.9355\n",
      "Epoch 43/100\n",
      "620/620 [==============================] - 0s 285us/step - loss: 0.1729 - acc: 0.9339\n",
      "Epoch 44/100\n",
      "620/620 [==============================] - 0s 265us/step - loss: 0.1623 - acc: 0.9435\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/620 [==============================] - 0s 293us/step - loss: 0.1571 - acc: 0.9387\n",
      "Epoch 46/100\n",
      "620/620 [==============================] - 0s 267us/step - loss: 0.1718 - acc: 0.9387\n",
      "Epoch 47/100\n",
      "620/620 [==============================] - 0s 302us/step - loss: 0.1597 - acc: 0.9435\n",
      "Epoch 48/100\n",
      "620/620 [==============================] - 0s 286us/step - loss: 0.1665 - acc: 0.9306\n",
      "Epoch 49/100\n",
      "620/620 [==============================] - 0s 291us/step - loss: 0.1418 - acc: 0.9387\n",
      "Epoch 50/100\n",
      "620/620 [==============================] - 0s 271us/step - loss: 0.1742 - acc: 0.9355\n",
      "Epoch 51/100\n",
      "620/620 [==============================] - 0s 298us/step - loss: 0.1696 - acc: 0.9387\n",
      "Epoch 52/100\n",
      "620/620 [==============================] - 0s 284us/step - loss: 0.1445 - acc: 0.9323\n",
      "Epoch 53/100\n",
      "620/620 [==============================] - 0s 295us/step - loss: 0.1552 - acc: 0.9355\n",
      "Epoch 54/100\n",
      "620/620 [==============================] - 0s 289us/step - loss: 0.1513 - acc: 0.9339\n",
      "Epoch 55/100\n",
      "620/620 [==============================] - 0s 272us/step - loss: 0.1671 - acc: 0.9387\n",
      "Epoch 56/100\n",
      "620/620 [==============================] - 0s 278us/step - loss: 0.1347 - acc: 0.9468\n",
      "Epoch 57/100\n",
      "620/620 [==============================] - 0s 276us/step - loss: 0.1465 - acc: 0.9403\n",
      "Epoch 58/100\n",
      "620/620 [==============================] - 0s 278us/step - loss: 0.1561 - acc: 0.9339\n",
      "Epoch 59/100\n",
      "620/620 [==============================] - 0s 302us/step - loss: 0.1363 - acc: 0.9581\n",
      "Epoch 60/100\n",
      "620/620 [==============================] - 0s 270us/step - loss: 0.1380 - acc: 0.9548\n",
      "Epoch 61/100\n",
      "620/620 [==============================] - 0s 300us/step - loss: 0.1693 - acc: 0.9387\n",
      "Epoch 62/100\n",
      "620/620 [==============================] - 0s 297us/step - loss: 0.1512 - acc: 0.9387\n",
      "Epoch 63/100\n",
      "620/620 [==============================] - 0s 413us/step - loss: 0.1242 - acc: 0.9532\n",
      "Epoch 64/100\n",
      "620/620 [==============================] - 0s 407us/step - loss: 0.1516 - acc: 0.9403\n",
      "Epoch 65/100\n",
      "620/620 [==============================] - 0s 444us/step - loss: 0.1315 - acc: 0.9532\n",
      "Epoch 66/100\n",
      "620/620 [==============================] - 0s 362us/step - loss: 0.1310 - acc: 0.9516\n",
      "Epoch 67/100\n",
      "620/620 [==============================] - 0s 315us/step - loss: 0.1341 - acc: 0.9532\n",
      "Epoch 68/100\n",
      "620/620 [==============================] - 0s 292us/step - loss: 0.1577 - acc: 0.9419\n",
      "Epoch 69/100\n",
      "620/620 [==============================] - 0s 294us/step - loss: 0.1108 - acc: 0.9597\n",
      "Epoch 70/100\n",
      "620/620 [==============================] - 0s 275us/step - loss: 0.1375 - acc: 0.9532\n",
      "Epoch 71/100\n",
      "620/620 [==============================] - 0s 302us/step - loss: 0.1174 - acc: 0.9581\n",
      "Epoch 72/100\n",
      "620/620 [==============================] - 0s 277us/step - loss: 0.1340 - acc: 0.9387\n",
      "Epoch 73/100\n",
      "620/620 [==============================] - 0s 303us/step - loss: 0.1490 - acc: 0.9419\n",
      "Epoch 74/100\n",
      "620/620 [==============================] - 0s 295us/step - loss: 0.1223 - acc: 0.9581\n",
      "Epoch 75/100\n",
      "620/620 [==============================] - 0s 291us/step - loss: 0.1311 - acc: 0.9403\n",
      "Epoch 76/100\n",
      "620/620 [==============================] - 0s 420us/step - loss: 0.1333 - acc: 0.9516\n",
      "Epoch 77/100\n",
      "620/620 [==============================] - 0s 300us/step - loss: 0.1160 - acc: 0.9629\n",
      "Epoch 78/100\n",
      "620/620 [==============================] - 0s 321us/step - loss: 0.1216 - acc: 0.9548\n",
      "Epoch 79/100\n",
      "620/620 [==============================] - 0s 306us/step - loss: 0.1094 - acc: 0.9548\n",
      "Epoch 80/100\n",
      "620/620 [==============================] - 0s 437us/step - loss: 0.1358 - acc: 0.9435\n",
      "Epoch 81/100\n",
      "620/620 [==============================] - 0s 427us/step - loss: 0.1396 - acc: 0.9500 0s - loss: 0.2081 - acc: 0.\n",
      "Epoch 82/100\n",
      "620/620 [==============================] - 0s 352us/step - loss: 0.1302 - acc: 0.9484\n",
      "Epoch 83/100\n",
      "620/620 [==============================] - 0s 340us/step - loss: 0.1328 - acc: 0.9419\n",
      "Epoch 84/100\n",
      "620/620 [==============================] - 0s 291us/step - loss: 0.1162 - acc: 0.9548\n",
      "Epoch 85/100\n",
      "620/620 [==============================] - 0s 314us/step - loss: 0.1229 - acc: 0.9484\n",
      "Epoch 86/100\n",
      "620/620 [==============================] - 0s 310us/step - loss: 0.1139 - acc: 0.9516\n",
      "Epoch 87/100\n",
      "620/620 [==============================] - 0s 366us/step - loss: 0.1258 - acc: 0.9548\n",
      "Epoch 88/100\n",
      "620/620 [==============================] - 0s 408us/step - loss: 0.1234 - acc: 0.9613\n",
      "Epoch 89/100\n",
      "620/620 [==============================] - 0s 553us/step - loss: 0.1055 - acc: 0.9613\n",
      "Epoch 90/100\n",
      "620/620 [==============================] - 0s 536us/step - loss: 0.1254 - acc: 0.9468\n",
      "Epoch 91/100\n",
      "620/620 [==============================] - 0s 521us/step - loss: 0.1226 - acc: 0.9565\n",
      "Epoch 92/100\n",
      "620/620 [==============================] - 0s 475us/step - loss: 0.1273 - acc: 0.9516\n",
      "Epoch 93/100\n",
      "620/620 [==============================] - 0s 538us/step - loss: 0.1400 - acc: 0.9419\n",
      "Epoch 94/100\n",
      "620/620 [==============================] - 0s 520us/step - loss: 0.1231 - acc: 0.9484\n",
      "Epoch 95/100\n",
      "620/620 [==============================] - 0s 375us/step - loss: 0.1117 - acc: 0.9581\n",
      "Epoch 96/100\n",
      "620/620 [==============================] - 0s 333us/step - loss: 0.1341 - acc: 0.9452 0s - loss: 0.1468 - acc: 0.939\n",
      "Epoch 97/100\n",
      "620/620 [==============================] - 0s 366us/step - loss: 0.0992 - acc: 0.9677\n",
      "Epoch 98/100\n",
      "620/620 [==============================] - 0s 340us/step - loss: 0.0948 - acc: 0.9581\n",
      "Epoch 99/100\n",
      "620/620 [==============================] - 0s 503us/step - loss: 0.0974 - acc: 0.9613\n",
      "Epoch 100/100\n",
      "620/620 [==============================] - 0s 334us/step - loss: 0.1189 - acc: 0.9581\n",
      "Epoch 1/100\n",
      "620/620 [==============================] - 6s 10ms/step - loss: 1.7578 - acc: 0.3532\n",
      "Epoch 2/100\n",
      "620/620 [==============================] - 0s 343us/step - loss: 1.1894 - acc: 0.5581\n",
      "Epoch 3/100\n",
      "620/620 [==============================] - 0s 368us/step - loss: 0.9618 - acc: 0.6661\n",
      "Epoch 4/100\n",
      "620/620 [==============================] - 0s 400us/step - loss: 0.7515 - acc: 0.7484\n",
      "Epoch 5/100\n",
      "620/620 [==============================] - 0s 336us/step - loss: 0.6880 - acc: 0.7887\n",
      "Epoch 6/100\n",
      "620/620 [==============================] - 0s 395us/step - loss: 0.5658 - acc: 0.8323\n",
      "Epoch 7/100\n",
      "620/620 [==============================] - 0s 317us/step - loss: 0.5364 - acc: 0.8435\n",
      "Epoch 8/100\n",
      "620/620 [==============================] - 0s 315us/step - loss: 0.4954 - acc: 0.8355\n",
      "Epoch 9/100\n",
      "620/620 [==============================] - 0s 342us/step - loss: 0.4431 - acc: 0.8468\n",
      "Epoch 10/100\n",
      "620/620 [==============================] - 0s 305us/step - loss: 0.4206 - acc: 0.8629\n",
      "Epoch 11/100\n",
      "620/620 [==============================] - 0s 328us/step - loss: 0.3486 - acc: 0.8903\n",
      "Epoch 12/100\n",
      "620/620 [==============================] - 0s 297us/step - loss: 0.3550 - acc: 0.8903\n",
      "Epoch 13/100\n",
      "620/620 [==============================] - 0s 362us/step - loss: 0.2889 - acc: 0.8919\n",
      "Epoch 14/100\n",
      "620/620 [==============================] - 0s 332us/step - loss: 0.2863 - acc: 0.9000\n",
      "Epoch 15/100\n",
      "620/620 [==============================] - 0s 340us/step - loss: 0.3419 - acc: 0.8839\n",
      "Epoch 16/100\n",
      "620/620 [==============================] - 0s 492us/step - loss: 0.2804 - acc: 0.8968\n",
      "Epoch 17/100\n",
      "620/620 [==============================] - 0s 366us/step - loss: 0.2812 - acc: 0.9065\n",
      "Epoch 18/100\n",
      "620/620 [==============================] - 0s 331us/step - loss: 0.2672 - acc: 0.9081\n",
      "Epoch 19/100\n",
      "620/620 [==============================] - 0s 342us/step - loss: 0.2566 - acc: 0.9097\n",
      "Epoch 20/100\n",
      "620/620 [==============================] - 0s 371us/step - loss: 0.2553 - acc: 0.8919\n",
      "Epoch 21/100\n",
      "620/620 [==============================] - 0s 406us/step - loss: 0.2540 - acc: 0.9081\n",
      "Epoch 22/100\n",
      "620/620 [==============================] - 0s 354us/step - loss: 0.2301 - acc: 0.9065 0s - loss: 0.2319 - acc: 0.904\n",
      "Epoch 23/100\n",
      "620/620 [==============================] - 0s 315us/step - loss: 0.1976 - acc: 0.9387\n",
      "Epoch 24/100\n",
      "620/620 [==============================] - 0s 319us/step - loss: 0.2312 - acc: 0.9065\n",
      "Epoch 25/100\n",
      "620/620 [==============================] - 0s 315us/step - loss: 0.2361 - acc: 0.9097\n",
      "Epoch 26/100\n",
      "620/620 [==============================] - 0s 310us/step - loss: 0.2264 - acc: 0.9097\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/620 [==============================] - 0s 355us/step - loss: 0.1979 - acc: 0.9145\n",
      "Epoch 28/100\n",
      "620/620 [==============================] - 0s 366us/step - loss: 0.2097 - acc: 0.9113\n",
      "Epoch 29/100\n",
      "620/620 [==============================] - 0s 327us/step - loss: 0.1965 - acc: 0.9226\n",
      "Epoch 30/100\n",
      "620/620 [==============================] - 0s 306us/step - loss: 0.1809 - acc: 0.9435\n",
      "Epoch 31/100\n",
      "620/620 [==============================] - 0s 427us/step - loss: 0.1789 - acc: 0.9290\n",
      "Epoch 32/100\n",
      "620/620 [==============================] - 0s 310us/step - loss: 0.1994 - acc: 0.9323\n",
      "Epoch 33/100\n",
      "620/620 [==============================] - 0s 335us/step - loss: 0.1864 - acc: 0.9339\n",
      "Epoch 34/100\n",
      "620/620 [==============================] - 0s 315us/step - loss: 0.1913 - acc: 0.9177\n",
      "Epoch 35/100\n",
      "620/620 [==============================] - 0s 330us/step - loss: 0.1777 - acc: 0.9161\n",
      "Epoch 36/100\n",
      "620/620 [==============================] - 0s 310us/step - loss: 0.1446 - acc: 0.9452 0s - loss: 0.1461 - acc: 0.944\n",
      "Epoch 37/100\n",
      "620/620 [==============================] - 0s 319us/step - loss: 0.1800 - acc: 0.9274\n",
      "Epoch 38/100\n",
      "620/620 [==============================] - 0s 320us/step - loss: 0.1719 - acc: 0.9323\n",
      "Epoch 39/100\n",
      "620/620 [==============================] - 0s 322us/step - loss: 0.2015 - acc: 0.9226\n",
      "Epoch 40/100\n",
      "620/620 [==============================] - 0s 309us/step - loss: 0.1568 - acc: 0.9371\n",
      "Epoch 41/100\n",
      "620/620 [==============================] - 0s 305us/step - loss: 0.1605 - acc: 0.9387\n",
      "Epoch 42/100\n",
      "620/620 [==============================] - 0s 349us/step - loss: 0.1809 - acc: 0.9355\n",
      "Epoch 43/100\n",
      "620/620 [==============================] - 0s 292us/step - loss: 0.1960 - acc: 0.9177\n",
      "Epoch 44/100\n",
      "620/620 [==============================] - 0s 382us/step - loss: 0.1795 - acc: 0.9339\n",
      "Epoch 45/100\n",
      "620/620 [==============================] - 0s 343us/step - loss: 0.1675 - acc: 0.9387\n",
      "Epoch 46/100\n",
      "620/620 [==============================] - 0s 327us/step - loss: 0.1516 - acc: 0.9355\n",
      "Epoch 47/100\n",
      "620/620 [==============================] - 0s 386us/step - loss: 0.1378 - acc: 0.9387 0s - loss: 0.1585 - acc: 0.93\n",
      "Epoch 48/100\n",
      "620/620 [==============================] - 0s 294us/step - loss: 0.1467 - acc: 0.9452\n",
      "Epoch 49/100\n",
      "620/620 [==============================] - 0s 332us/step - loss: 0.1903 - acc: 0.9323\n",
      "Epoch 50/100\n",
      "620/620 [==============================] - 0s 344us/step - loss: 0.1759 - acc: 0.9323\n",
      "Epoch 51/100\n",
      "620/620 [==============================] - 0s 366us/step - loss: 0.1694 - acc: 0.9323\n",
      "Epoch 52/100\n",
      "620/620 [==============================] - 0s 426us/step - loss: 0.1730 - acc: 0.9323\n",
      "Epoch 53/100\n",
      "620/620 [==============================] - 0s 347us/step - loss: 0.1717 - acc: 0.9306\n",
      "Epoch 54/100\n",
      "620/620 [==============================] - 0s 330us/step - loss: 0.1554 - acc: 0.9435\n",
      "Epoch 55/100\n",
      "620/620 [==============================] - 0s 306us/step - loss: 0.1496 - acc: 0.9403\n",
      "Epoch 56/100\n",
      "620/620 [==============================] - 0s 346us/step - loss: 0.1403 - acc: 0.9500\n",
      "Epoch 57/100\n",
      "620/620 [==============================] - 0s 346us/step - loss: 0.1356 - acc: 0.9532\n",
      "Epoch 58/100\n",
      "620/620 [==============================] - 0s 322us/step - loss: 0.1380 - acc: 0.9484\n",
      "Epoch 59/100\n",
      "620/620 [==============================] - 0s 323us/step - loss: 0.1322 - acc: 0.9435\n",
      "Epoch 60/100\n",
      "620/620 [==============================] - 0s 293us/step - loss: 0.1558 - acc: 0.9387\n",
      "Epoch 61/100\n",
      "620/620 [==============================] - 0s 329us/step - loss: 0.1470 - acc: 0.9387\n",
      "Epoch 62/100\n",
      "620/620 [==============================] - 0s 332us/step - loss: 0.1733 - acc: 0.9355\n",
      "Epoch 63/100\n",
      "620/620 [==============================] - 0s 313us/step - loss: 0.1419 - acc: 0.9532\n",
      "Epoch 64/100\n",
      "620/620 [==============================] - 0s 310us/step - loss: 0.1655 - acc: 0.9371\n",
      "Epoch 65/100\n",
      "620/620 [==============================] - 0s 291us/step - loss: 0.1298 - acc: 0.9532\n",
      "Epoch 66/100\n",
      "620/620 [==============================] - 0s 349us/step - loss: 0.1422 - acc: 0.9452\n",
      "Epoch 67/100\n",
      "620/620 [==============================] - 0s 291us/step - loss: 0.1297 - acc: 0.9484\n",
      "Epoch 68/100\n",
      "620/620 [==============================] - 0s 346us/step - loss: 0.1496 - acc: 0.9452\n",
      "Epoch 69/100\n",
      "620/620 [==============================] - 0s 311us/step - loss: 0.1443 - acc: 0.9371\n",
      "Epoch 70/100\n",
      "620/620 [==============================] - 0s 445us/step - loss: 0.1433 - acc: 0.9435\n",
      "Epoch 71/100\n",
      "620/620 [==============================] - 0s 370us/step - loss: 0.1293 - acc: 0.9452\n",
      "Epoch 72/100\n",
      "620/620 [==============================] - 0s 397us/step - loss: 0.1329 - acc: 0.9516\n",
      "Epoch 73/100\n",
      "620/620 [==============================] - 0s 378us/step - loss: 0.1315 - acc: 0.9452\n",
      "Epoch 74/100\n",
      "620/620 [==============================] - 0s 403us/step - loss: 0.1162 - acc: 0.9565\n",
      "Epoch 75/100\n",
      "620/620 [==============================] - 0s 363us/step - loss: 0.1215 - acc: 0.9516\n",
      "Epoch 76/100\n",
      "620/620 [==============================] - 0s 385us/step - loss: 0.1221 - acc: 0.9548\n",
      "Epoch 77/100\n",
      "620/620 [==============================] - 0s 358us/step - loss: 0.1051 - acc: 0.9613\n",
      "Epoch 78/100\n",
      "620/620 [==============================] - 0s 373us/step - loss: 0.1161 - acc: 0.9613\n",
      "Epoch 79/100\n",
      "620/620 [==============================] - 0s 383us/step - loss: 0.1301 - acc: 0.9500\n",
      "Epoch 80/100\n",
      "620/620 [==============================] - 0s 383us/step - loss: 0.1132 - acc: 0.9677\n",
      "Epoch 81/100\n",
      "620/620 [==============================] - 0s 311us/step - loss: 0.1211 - acc: 0.9500\n",
      "Epoch 82/100\n",
      "620/620 [==============================] - 0s 328us/step - loss: 0.1081 - acc: 0.9694\n",
      "Epoch 83/100\n",
      "620/620 [==============================] - 0s 311us/step - loss: 0.1208 - acc: 0.9613\n",
      "Epoch 84/100\n",
      "620/620 [==============================] - 0s 349us/step - loss: 0.1324 - acc: 0.9435\n",
      "Epoch 85/100\n",
      "620/620 [==============================] - 0s 310us/step - loss: 0.1264 - acc: 0.9435\n",
      "Epoch 86/100\n",
      "620/620 [==============================] - 0s 320us/step - loss: 0.1299 - acc: 0.9581\n",
      "Epoch 87/100\n",
      "620/620 [==============================] - 0s 301us/step - loss: 0.1192 - acc: 0.9565\n",
      "Epoch 88/100\n",
      "620/620 [==============================] - 0s 318us/step - loss: 0.1081 - acc: 0.9565\n",
      "Epoch 89/100\n",
      "620/620 [==============================] - 0s 323us/step - loss: 0.1111 - acc: 0.9613\n",
      "Epoch 90/100\n",
      "620/620 [==============================] - 0s 326us/step - loss: 0.1115 - acc: 0.9629\n",
      "Epoch 91/100\n",
      "620/620 [==============================] - 0s 406us/step - loss: 0.1217 - acc: 0.9435\n",
      "Epoch 92/100\n",
      "620/620 [==============================] - 0s 372us/step - loss: 0.1012 - acc: 0.9629\n",
      "Epoch 93/100\n",
      "620/620 [==============================] - 0s 385us/step - loss: 0.1160 - acc: 0.9532\n",
      "Epoch 94/100\n",
      "620/620 [==============================] - 0s 330us/step - loss: 0.1281 - acc: 0.9452\n",
      "Epoch 95/100\n",
      "620/620 [==============================] - 0s 298us/step - loss: 0.1359 - acc: 0.9403\n",
      "Epoch 96/100\n",
      "620/620 [==============================] - 0s 337us/step - loss: 0.1098 - acc: 0.9629\n",
      "Epoch 97/100\n",
      "620/620 [==============================] - 0s 300us/step - loss: 0.1203 - acc: 0.9597\n",
      "Epoch 98/100\n",
      "620/620 [==============================] - 0s 354us/step - loss: 0.1158 - acc: 0.9581\n",
      "Epoch 99/100\n",
      "620/620 [==============================] - 0s 354us/step - loss: 0.1117 - acc: 0.9565\n",
      "Epoch 100/100\n",
      "620/620 [==============================] - 0s 299us/step - loss: 0.1115 - acc: 0.9532\n",
      "Epoch 1/100\n",
      "620/620 [==============================] - 5s 8ms/step - loss: 1.7333 - acc: 0.3226\n",
      "Epoch 2/100\n",
      "620/620 [==============================] - 0s 358us/step - loss: 1.2343 - acc: 0.5242\n",
      "Epoch 3/100\n",
      "620/620 [==============================] - 0s 391us/step - loss: 0.9970 - acc: 0.6435\n",
      "Epoch 4/100\n",
      "620/620 [==============================] - 0s 278us/step - loss: 0.8114 - acc: 0.7258\n",
      "Epoch 5/100\n",
      "620/620 [==============================] - 0s 298us/step - loss: 0.7202 - acc: 0.7871\n",
      "Epoch 6/100\n",
      "620/620 [==============================] - 0s 304us/step - loss: 0.5431 - acc: 0.8258\n",
      "Epoch 7/100\n",
      "620/620 [==============================] - 0s 303us/step - loss: 0.4963 - acc: 0.8581\n",
      "Epoch 8/100\n",
      "620/620 [==============================] - 0s 272us/step - loss: 0.5065 - acc: 0.8274\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/620 [==============================] - 0s 301us/step - loss: 0.4279 - acc: 0.8548\n",
      "Epoch 10/100\n",
      "620/620 [==============================] - 0s 271us/step - loss: 0.4004 - acc: 0.8565\n",
      "Epoch 11/100\n",
      "620/620 [==============================] - 0s 287us/step - loss: 0.3806 - acc: 0.8726\n",
      "Epoch 12/100\n",
      "620/620 [==============================] - 0s 300us/step - loss: 0.3609 - acc: 0.8774\n",
      "Epoch 13/100\n",
      "620/620 [==============================] - 0s 303us/step - loss: 0.3281 - acc: 0.8968\n",
      "Epoch 14/100\n",
      "620/620 [==============================] - 0s 305us/step - loss: 0.2824 - acc: 0.9032\n",
      "Epoch 15/100\n",
      "620/620 [==============================] - 0s 285us/step - loss: 0.3112 - acc: 0.8887\n",
      "Epoch 16/100\n",
      "620/620 [==============================] - 0s 298us/step - loss: 0.2921 - acc: 0.8984 0s - loss: 0.2970 - acc: 0.90\n",
      "Epoch 17/100\n",
      "620/620 [==============================] - 0s 274us/step - loss: 0.2991 - acc: 0.8871\n",
      "Epoch 18/100\n",
      "620/620 [==============================] - 0s 277us/step - loss: 0.2661 - acc: 0.9097\n",
      "Epoch 19/100\n",
      "620/620 [==============================] - 0s 283us/step - loss: 0.2684 - acc: 0.9081\n",
      "Epoch 20/100\n",
      "620/620 [==============================] - 0s 368us/step - loss: 0.2417 - acc: 0.9129\n",
      "Epoch 21/100\n",
      "620/620 [==============================] - 0s 360us/step - loss: 0.2423 - acc: 0.9145\n",
      "Epoch 22/100\n",
      "620/620 [==============================] - 0s 408us/step - loss: 0.2156 - acc: 0.9177\n",
      "Epoch 23/100\n",
      "620/620 [==============================] - 0s 361us/step - loss: 0.2359 - acc: 0.9048\n",
      "Epoch 24/100\n",
      "620/620 [==============================] - 0s 225us/step - loss: 0.2037 - acc: 0.9161\n",
      "Epoch 25/100\n",
      "620/620 [==============================] - 0s 255us/step - loss: 0.2196 - acc: 0.9194\n",
      "Epoch 26/100\n",
      "620/620 [==============================] - 0s 278us/step - loss: 0.2234 - acc: 0.9032\n",
      "Epoch 27/100\n",
      "620/620 [==============================] - 0s 290us/step - loss: 0.2285 - acc: 0.9210\n",
      "Epoch 28/100\n",
      "620/620 [==============================] - 0s 292us/step - loss: 0.2212 - acc: 0.9177\n",
      "Epoch 29/100\n",
      "620/620 [==============================] - 0s 295us/step - loss: 0.2092 - acc: 0.9145\n",
      "Epoch 30/100\n",
      "620/620 [==============================] - 0s 283us/step - loss: 0.2020 - acc: 0.9210\n",
      "Epoch 31/100\n",
      "620/620 [==============================] - 0s 276us/step - loss: 0.1987 - acc: 0.9323\n",
      "Epoch 32/100\n",
      "620/620 [==============================] - 0s 297us/step - loss: 0.1917 - acc: 0.9371\n",
      "Epoch 33/100\n",
      "620/620 [==============================] - 0s 292us/step - loss: 0.1824 - acc: 0.9339\n",
      "Epoch 34/100\n",
      "620/620 [==============================] - 0s 298us/step - loss: 0.1861 - acc: 0.9274\n",
      "Epoch 35/100\n",
      "620/620 [==============================] - 0s 299us/step - loss: 0.2290 - acc: 0.9161\n",
      "Epoch 36/100\n",
      "620/620 [==============================] - 0s 261us/step - loss: 0.1915 - acc: 0.9339\n",
      "Epoch 37/100\n",
      "620/620 [==============================] - 0s 285us/step - loss: 0.2074 - acc: 0.9226\n",
      "Epoch 38/100\n",
      "620/620 [==============================] - 0s 277us/step - loss: 0.1949 - acc: 0.9290\n",
      "Epoch 39/100\n",
      "620/620 [==============================] - 0s 294us/step - loss: 0.1787 - acc: 0.9355\n",
      "Epoch 40/100\n",
      "620/620 [==============================] - 0s 275us/step - loss: 0.1849 - acc: 0.9258\n",
      "Epoch 41/100\n",
      "620/620 [==============================] - 0s 303us/step - loss: 0.1571 - acc: 0.9468\n",
      "Epoch 42/100\n",
      "620/620 [==============================] - 0s 276us/step - loss: 0.1648 - acc: 0.9371\n",
      "Epoch 43/100\n",
      "620/620 [==============================] - 0s 279us/step - loss: 0.1955 - acc: 0.9226 0s - loss: 0.2036 - acc: 0.926\n",
      "Epoch 44/100\n",
      "620/620 [==============================] - 0s 301us/step - loss: 0.1549 - acc: 0.9306\n",
      "Epoch 45/100\n",
      "620/620 [==============================] - 0s 302us/step - loss: 0.1559 - acc: 0.9500\n",
      "Epoch 46/100\n",
      "620/620 [==============================] - 0s 391us/step - loss: 0.1528 - acc: 0.9452\n",
      "Epoch 47/100\n",
      "620/620 [==============================] - 0s 342us/step - loss: 0.1797 - acc: 0.9306\n",
      "Epoch 48/100\n",
      "620/620 [==============================] - 0s 302us/step - loss: 0.1769 - acc: 0.9258\n",
      "Epoch 49/100\n",
      "620/620 [==============================] - 0s 322us/step - loss: 0.1588 - acc: 0.9339\n",
      "Epoch 50/100\n",
      "620/620 [==============================] - 0s 271us/step - loss: 0.1789 - acc: 0.9242\n",
      "Epoch 51/100\n",
      "620/620 [==============================] - 0s 298us/step - loss: 0.1636 - acc: 0.9419\n",
      "Epoch 52/100\n",
      "620/620 [==============================] - 0s 274us/step - loss: 0.1396 - acc: 0.9500\n",
      "Epoch 53/100\n",
      "620/620 [==============================] - 0s 294us/step - loss: 0.1821 - acc: 0.9323\n",
      "Epoch 54/100\n",
      "620/620 [==============================] - 0s 288us/step - loss: 0.1533 - acc: 0.9403\n",
      "Epoch 55/100\n",
      "620/620 [==============================] - 0s 285us/step - loss: 0.1530 - acc: 0.9403\n",
      "Epoch 56/100\n",
      "620/620 [==============================] - 0s 268us/step - loss: 0.1642 - acc: 0.9355\n",
      "Epoch 57/100\n",
      "620/620 [==============================] - 0s 331us/step - loss: 0.1320 - acc: 0.9452\n",
      "Epoch 58/100\n",
      "620/620 [==============================] - 0s 311us/step - loss: 0.1535 - acc: 0.9435\n",
      "Epoch 59/100\n",
      "620/620 [==============================] - 0s 304us/step - loss: 0.1362 - acc: 0.9548\n",
      "Epoch 60/100\n",
      "620/620 [==============================] - 0s 276us/step - loss: 0.1340 - acc: 0.9484\n",
      "Epoch 61/100\n",
      "620/620 [==============================] - 0s 293us/step - loss: 0.1382 - acc: 0.9403\n",
      "Epoch 62/100\n",
      "620/620 [==============================] - 0s 284us/step - loss: 0.1156 - acc: 0.9565\n",
      "Epoch 63/100\n",
      "620/620 [==============================] - 0s 297us/step - loss: 0.1374 - acc: 0.9468\n",
      "Epoch 64/100\n",
      "620/620 [==============================] - 0s 273us/step - loss: 0.1404 - acc: 0.9484\n",
      "Epoch 65/100\n",
      "620/620 [==============================] - 0s 412us/step - loss: 0.1284 - acc: 0.9597\n",
      "Epoch 66/100\n",
      "620/620 [==============================] - 0s 347us/step - loss: 0.1424 - acc: 0.9484\n",
      "Epoch 67/100\n",
      "620/620 [==============================] - 0s 345us/step - loss: 0.1402 - acc: 0.9435\n",
      "Epoch 68/100\n",
      "620/620 [==============================] - 0s 320us/step - loss: 0.1592 - acc: 0.9323\n",
      "Epoch 69/100\n",
      "620/620 [==============================] - 0s 282us/step - loss: 0.1324 - acc: 0.9484\n",
      "Epoch 70/100\n",
      "620/620 [==============================] - 0s 332us/step - loss: 0.1243 - acc: 0.9548\n",
      "Epoch 71/100\n",
      "620/620 [==============================] - 0s 247us/step - loss: 0.1072 - acc: 0.9613\n",
      "Epoch 72/100\n",
      "620/620 [==============================] - 0s 397us/step - loss: 0.1094 - acc: 0.9532\n",
      "Epoch 73/100\n",
      "620/620 [==============================] - 0s 340us/step - loss: 0.1175 - acc: 0.9532\n",
      "Epoch 74/100\n",
      "620/620 [==============================] - 0s 304us/step - loss: 0.1127 - acc: 0.9581\n",
      "Epoch 75/100\n",
      "620/620 [==============================] - 0s 283us/step - loss: 0.1289 - acc: 0.9500\n",
      "Epoch 76/100\n",
      "620/620 [==============================] - 0s 282us/step - loss: 0.1252 - acc: 0.9484\n",
      "Epoch 77/100\n",
      "620/620 [==============================] - 0s 230us/step - loss: 0.1308 - acc: 0.9532\n",
      "Epoch 78/100\n",
      "620/620 [==============================] - 0s 288us/step - loss: 0.1146 - acc: 0.9548\n",
      "Epoch 79/100\n",
      "620/620 [==============================] - 0s 284us/step - loss: 0.1287 - acc: 0.9484\n",
      "Epoch 80/100\n",
      "620/620 [==============================] - 0s 306us/step - loss: 0.1579 - acc: 0.9435\n",
      "Epoch 81/100\n",
      "620/620 [==============================] - 0s 277us/step - loss: 0.1389 - acc: 0.9452 0s - loss: 0.1572 - acc: 0.9\n",
      "Epoch 82/100\n",
      "620/620 [==============================] - 0s 312us/step - loss: 0.1412 - acc: 0.9403\n",
      "Epoch 83/100\n",
      "620/620 [==============================] - 0s 307us/step - loss: 0.1339 - acc: 0.9548\n",
      "Epoch 84/100\n",
      "620/620 [==============================] - 0s 332us/step - loss: 0.1105 - acc: 0.9645\n",
      "Epoch 85/100\n",
      "620/620 [==============================] - 0s 328us/step - loss: 0.1156 - acc: 0.9516\n",
      "Epoch 86/100\n",
      "620/620 [==============================] - 0s 284us/step - loss: 0.1138 - acc: 0.9565\n",
      "Epoch 87/100\n",
      "620/620 [==============================] - 0s 347us/step - loss: 0.1439 - acc: 0.9452\n",
      "Epoch 88/100\n",
      "620/620 [==============================] - 0s 299us/step - loss: 0.1395 - acc: 0.9339\n",
      "Epoch 89/100\n",
      "620/620 [==============================] - 0s 328us/step - loss: 0.1118 - acc: 0.9613\n",
      "Epoch 90/100\n",
      "620/620 [==============================] - 0s 284us/step - loss: 0.1107 - acc: 0.9581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "620/620 [==============================] - 0s 283us/step - loss: 0.1172 - acc: 0.9629\n",
      "Epoch 92/100\n",
      "620/620 [==============================] - 0s 271us/step - loss: 0.1343 - acc: 0.9516\n",
      "Epoch 93/100\n",
      "620/620 [==============================] - 0s 296us/step - loss: 0.1501 - acc: 0.9403\n",
      "Epoch 94/100\n",
      "620/620 [==============================] - 0s 292us/step - loss: 0.1258 - acc: 0.9532\n",
      "Epoch 95/100\n",
      "620/620 [==============================] - 0s 297us/step - loss: 0.1218 - acc: 0.9468\n",
      "Epoch 96/100\n",
      "620/620 [==============================] - 0s 289us/step - loss: 0.1140 - acc: 0.9613\n",
      "Epoch 97/100\n",
      "620/620 [==============================] - 0s 276us/step - loss: 0.1138 - acc: 0.9597\n",
      "Epoch 98/100\n",
      "620/620 [==============================] - 0s 276us/step - loss: 0.1234 - acc: 0.9468\n",
      "Epoch 99/100\n",
      "620/620 [==============================] - 0s 304us/step - loss: 0.1346 - acc: 0.9565\n",
      "Epoch 100/100\n",
      "620/620 [==============================] - 0s 289us/step - loss: 0.1072 - acc: 0.9581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('model1',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x00000229BFD964C8>),\n",
       "                             ('model2',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x00000229BFDC7608>),\n",
       "                             ('model3',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x00000229BFD96588>),\n",
       "                             ('model4',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x00000229BFD96D48>),\n",
       "                             ('model5',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x00000229BFD966C8>)],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_clf.fit(x_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_predicted = ensemble_clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:  0.9790322580645161\n"
     ]
    }
   ],
   "source": [
    "print('Acc: ', accuracy_score(ytrain_predicted, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model produces near 98% of accuracy, which is rather improved from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_predicted = ensemble_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2,\n",
       "       2, 2, 4, 2, 3, 3, 2, 2, 2, 2, 2, 3, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2,\n",
       "       2, 2, 2, 2, 3, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 3, 2, 2, 2,\n",
       "       2, 2, 2, 2, 0, 4, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 4, 2, 2, 3, 1, 2, 1, 2, 3,\n",
       "       2, 2, 2, 2, 2, 3, 2, 2, 4, 2, 2, 2, 4, 2, 2, 4, 2, 2, 1, 4, 2, 3,\n",
       "       2, 2, 2, 2, 1, 1, 2, 1, 2, 3, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2,\n",
       "       4, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 3, 2, 4, 2, 2, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 3, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 4, 3, 2, 2, 1, 1,\n",
       "       2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_array=to_categorical(ytest_predicted).astype(int)\n",
    "result=pd.DataFrame(data=sub_array,  columns=[0, 1,2,3,4])\n",
    "result.to_excel('adam.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  0  0  1  0  0\n",
       "1  0  0  0  1  0\n",
       "2  0  0  1  0  0\n",
       "3  0  0  0  1  0\n",
       "4  0  0  1  0  0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
