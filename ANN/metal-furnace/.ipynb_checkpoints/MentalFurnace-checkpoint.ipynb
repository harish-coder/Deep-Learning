{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preparation Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "##Model Library\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from keras.layers import Dropout,ELU\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from keras_radam import RAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_train  = pd.read_csv(\"Train.csv\")\n",
    "mf_test = pd.read_csv(\"Test.csv\")\n",
    "sb = pd.read_excel('Sample_Submission.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.848564</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>-0.461423</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>1.305455</td>\n",
       "      <td>2.329398</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>-1.080663</td>\n",
       "      <td>0.443257</td>\n",
       "      <td>-0.406121</td>\n",
       "      <td>-0.687687</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>3.727218</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.825098</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>3.032397</td>\n",
       "      <td>-2.442599</td>\n",
       "      <td>1.305455</td>\n",
       "      <td>-0.276144</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>-1.080663</td>\n",
       "      <td>-0.232546</td>\n",
       "      <td>-0.406366</td>\n",
       "      <td>-0.687687</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>-0.232472</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.848564</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>-0.461423</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>1.305455</td>\n",
       "      <td>2.329398</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>0.925358</td>\n",
       "      <td>1.459782</td>\n",
       "      <td>1.221876</td>\n",
       "      <td>1.877777</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>-0.232472</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.511733</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>-0.461423</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>-0.525726</td>\n",
       "      <td>-0.276144</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>0.925358</td>\n",
       "      <td>-0.008030</td>\n",
       "      <td>-0.406366</td>\n",
       "      <td>1.504523</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>-0.232472</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.825098</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>-0.461423</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>-0.525726</td>\n",
       "      <td>-0.276144</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>0.925358</td>\n",
       "      <td>-0.573268</td>\n",
       "      <td>-1.164793</td>\n",
       "      <td>1.877777</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>-0.232472</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0       f1        f2        f3        f4        f5        f6  \\\n",
       "0  1.848564 -0.26425 -0.461423  0.409400  1.305455  2.329398  0.370965   \n",
       "1 -0.825098 -0.26425  3.032397 -2.442599  1.305455 -0.276144  0.370965   \n",
       "2  1.848564 -0.26425 -0.461423  0.409400  1.305455  2.329398  0.370965   \n",
       "3  0.511733 -0.26425 -0.461423  0.409400 -0.525726 -0.276144  0.370965   \n",
       "4 -0.825098 -0.26425 -0.461423  0.409400 -0.525726 -0.276144  0.370965   \n",
       "\n",
       "         f7        f8   f9  ...       f19       f20       f21       f22  \\\n",
       "0  0.090167  0.107958  0.0  ...  0.085505  0.233285 -1.080663  0.443257   \n",
       "1  0.090167  0.107958  0.0  ...  0.085505  0.233285 -1.080663 -0.232546   \n",
       "2  0.090167  0.107958  0.0  ...  0.085505  0.233285  0.925358  1.459782   \n",
       "3  0.090167  0.107958  0.0  ...  0.085505  0.233285  0.925358 -0.008030   \n",
       "4  0.090167  0.107958  0.0  ...  0.085505  0.233285  0.925358 -0.573268   \n",
       "\n",
       "        f23       f24       f25       f26       f27  grade  \n",
       "0 -0.406121 -0.687687  0.271886  3.727218  0.102129      2  \n",
       "1 -0.406366 -0.687687  0.271886 -0.232472  0.102129      4  \n",
       "2  1.221876  1.877777  0.271886 -0.232472  0.102129      2  \n",
       "3 -0.406366  1.504523  0.271886 -0.232472  0.102129      2  \n",
       "4 -1.164793  1.877777  0.271886 -0.232472  0.102129      2  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 3, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_train['grade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.837812</td>\n",
       "      <td>-0.273636</td>\n",
       "      <td>1.276580</td>\n",
       "      <td>0.463262</td>\n",
       "      <td>-0.585142</td>\n",
       "      <td>-0.24287</td>\n",
       "      <td>0.349804</td>\n",
       "      <td>0.12356</td>\n",
       "      <td>0.166795</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197642</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.886135</td>\n",
       "      <td>-0.568935</td>\n",
       "      <td>1.100428</td>\n",
       "      <td>-0.244589</td>\n",
       "      <td>0.229718</td>\n",
       "      <td>-0.217109</td>\n",
       "      <td>0.087039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.078087</td>\n",
       "      <td>-0.273636</td>\n",
       "      <td>-0.496119</td>\n",
       "      <td>0.463262</td>\n",
       "      <td>-2.438092</td>\n",
       "      <td>-0.24287</td>\n",
       "      <td>0.349804</td>\n",
       "      <td>0.12356</td>\n",
       "      <td>0.166795</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.059644</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.886135</td>\n",
       "      <td>0.504299</td>\n",
       "      <td>-0.434268</td>\n",
       "      <td>-0.244040</td>\n",
       "      <td>0.229718</td>\n",
       "      <td>-0.217109</td>\n",
       "      <td>0.087039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.837812</td>\n",
       "      <td>-0.273636</td>\n",
       "      <td>1.276580</td>\n",
       "      <td>0.463262</td>\n",
       "      <td>-0.585142</td>\n",
       "      <td>-0.24287</td>\n",
       "      <td>0.349804</td>\n",
       "      <td>0.12356</td>\n",
       "      <td>0.166795</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197642</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>-1.128496</td>\n",
       "      <td>-0.568935</td>\n",
       "      <td>-0.434268</td>\n",
       "      <td>-0.662763</td>\n",
       "      <td>0.229718</td>\n",
       "      <td>-0.217109</td>\n",
       "      <td>0.087039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.837812</td>\n",
       "      <td>-0.273636</td>\n",
       "      <td>-0.496119</td>\n",
       "      <td>0.463262</td>\n",
       "      <td>1.267808</td>\n",
       "      <td>-0.24287</td>\n",
       "      <td>-2.858743</td>\n",
       "      <td>0.12356</td>\n",
       "      <td>0.166795</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.059644</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>-1.128496</td>\n",
       "      <td>-0.449819</td>\n",
       "      <td>-1.918647</td>\n",
       "      <td>-0.662763</td>\n",
       "      <td>0.229718</td>\n",
       "      <td>-0.217109</td>\n",
       "      <td>0.087039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.837812</td>\n",
       "      <td>-0.273636</td>\n",
       "      <td>-0.496119</td>\n",
       "      <td>0.463262</td>\n",
       "      <td>-0.585142</td>\n",
       "      <td>-0.24287</td>\n",
       "      <td>-2.858743</td>\n",
       "      <td>0.12356</td>\n",
       "      <td>0.166795</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197642</td>\n",
       "      <td>0.06143</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>-1.128496</td>\n",
       "      <td>-0.568935</td>\n",
       "      <td>-0.434268</td>\n",
       "      <td>-0.662763</td>\n",
       "      <td>0.229718</td>\n",
       "      <td>-0.217109</td>\n",
       "      <td>0.087039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4       f5        f6  \\\n",
       "0 -0.837812 -0.273636  1.276580  0.463262 -0.585142 -0.24287  0.349804   \n",
       "1  2.078087 -0.273636 -0.496119  0.463262 -2.438092 -0.24287  0.349804   \n",
       "2 -0.837812 -0.273636  1.276580  0.463262 -0.585142 -0.24287  0.349804   \n",
       "3 -0.837812 -0.273636 -0.496119  0.463262  1.267808 -0.24287 -2.858743   \n",
       "4 -0.837812 -0.273636 -0.496119  0.463262 -0.585142 -0.24287 -2.858743   \n",
       "\n",
       "        f7        f8       f9  ...       f18      f19      f20       f21  \\\n",
       "0  0.12356  0.166795  0.06143  ...  0.197642  0.06143  0.27735  0.886135   \n",
       "1  0.12356  0.166795  0.06143  ... -5.059644  0.06143  0.27735  0.886135   \n",
       "2  0.12356  0.166795  0.06143  ...  0.197642  0.06143  0.27735 -1.128496   \n",
       "3  0.12356  0.166795  0.06143  ... -5.059644  0.06143  0.27735 -1.128496   \n",
       "4  0.12356  0.166795  0.06143  ...  0.197642  0.06143  0.27735 -1.128496   \n",
       "\n",
       "        f22       f23       f24       f25       f26       f27  \n",
       "0 -0.568935  1.100428 -0.244589  0.229718 -0.217109  0.087039  \n",
       "1  0.504299 -0.434268 -0.244040  0.229718 -0.217109  0.087039  \n",
       "2 -0.568935 -0.434268 -0.662763  0.229718 -0.217109  0.087039  \n",
       "3 -0.449819 -1.918647 -0.662763  0.229718 -0.217109  0.087039  \n",
       "4 -0.568935 -0.434268 -0.662763  0.229718 -0.217109  0.087039  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  0  0  1  0  0\n",
       "1  0  0  0  1  0\n",
       "2  0  0  1  0  0\n",
       "3  0  0  0  1  0\n",
       "4  0  0  1  0  0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mf_train.drop(columns=['grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = mf_train['grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = mf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "x_std = std.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_std.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=mf_train[['grade']].values\n",
    "y_train = y_train.reshape(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network():\n",
    "    classifier = Sequential()\n",
    "\n",
    "     # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = 50, kernel_initializer = 'he_normal', activation = 'elu', input_dim = 28))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 50, kernel_initializer = 'he_normal', activation = 'elu'))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    \n",
    "     # Adding the third hidden layer\n",
    "    classifier.add(Dense(units = 50, kernel_initializer = 'he_normal', activation = 'elu'))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    \n",
    "     # Adding the four hidden layer\n",
    "    classifier.add(Dense(units = 50, kernel_initializer = 'he_normal', activation = 'elu'))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    \n",
    "\n",
    "    classifier.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    classifier.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])   \n",
    "    ##classifier.compile(RAdam(), loss='categorical_crossentropy', metrics=['acc'])   \n",
    "    return classifier;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 5 models to ensemble\n",
    "model1 = KerasClassifier(build_fn = neural_network, epochs = 100)\n",
    "model2 = KerasClassifier(build_fn = neural_network, epochs = 100)\n",
    "model3 = KerasClassifier(build_fn = neural_network, epochs = 100)\n",
    "model4 = KerasClassifier(build_fn = neural_network, epochs = 100)\n",
    "model5 = KerasClassifier(build_fn = neural_network, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_clf = VotingClassifier(estimators = [('model1', model1), ('model2', model2), ('model3', model3), ('model4', model4), ('model5', model5)], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('model1',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x000002476DA64FC8>),\n",
       "                             ('model2',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x000002476DA64F88>),\n",
       "                             ('model3',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x000002476E160888>),\n",
       "                             ('model4',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x000002476DA6D188>),\n",
       "                             ('model5',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x000002476DA6D088>)],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 2.3274 - acc: 0.1565\n",
      "Epoch 2/100\n",
      "620/620 [==============================] - 0s 142us/step - loss: 2.3005 - acc: 0.1661\n",
      "Epoch 3/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.2934 - acc: 0.1565\n",
      "Epoch 4/100\n",
      "620/620 [==============================] - 0s 135us/step - loss: 2.2981 - acc: 0.1694\n",
      "Epoch 5/100\n",
      "620/620 [==============================] - 0s 135us/step - loss: 2.2379 - acc: 0.1774\n",
      "Epoch 6/100\n",
      "620/620 [==============================] - 0s 132us/step - loss: 2.2187 - acc: 0.1823\n",
      "Epoch 7/100\n",
      "620/620 [==============================] - 0s 132us/step - loss: 2.3232 - acc: 0.1661\n",
      "Epoch 8/100\n",
      "620/620 [==============================] - 0s 145us/step - loss: 2.2848 - acc: 0.1710\n",
      "Epoch 9/100\n",
      "620/620 [==============================] - 0s 135us/step - loss: 2.3129 - acc: 0.1677\n",
      "Epoch 10/100\n",
      "620/620 [==============================] - 0s 139us/step - loss: 2.2926 - acc: 0.1855\n",
      "Epoch 11/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.2978 - acc: 0.1645\n",
      "Epoch 12/100\n",
      "620/620 [==============================] - 0s 121us/step - loss: 2.3062 - acc: 0.1677\n",
      "Epoch 13/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.2871 - acc: 0.1613\n",
      "Epoch 14/100\n",
      "620/620 [==============================] - 0s 123us/step - loss: 2.2581 - acc: 0.1710\n",
      "Epoch 15/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.3405 - acc: 0.1694\n",
      "Epoch 16/100\n",
      "620/620 [==============================] - 0s 131us/step - loss: 2.2515 - acc: 0.1661\n",
      "Epoch 17/100\n",
      "620/620 [==============================] - 0s 123us/step - loss: 2.2714 - acc: 0.1903\n",
      "Epoch 18/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.3363 - acc: 0.1742\n",
      "Epoch 19/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.2803 - acc: 0.1823\n",
      "Epoch 20/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.2675 - acc: 0.1726\n",
      "Epoch 21/100\n",
      "620/620 [==============================] - 0s 129us/step - loss: 2.3073 - acc: 0.1581\n",
      "Epoch 22/100\n",
      "620/620 [==============================] - 0s 129us/step - loss: 2.3124 - acc: 0.1484\n",
      "Epoch 23/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.3021 - acc: 0.1597\n",
      "Epoch 24/100\n",
      "620/620 [==============================] - 0s 147us/step - loss: 2.3019 - acc: 0.1887\n",
      "Epoch 25/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.2623 - acc: 0.1758\n",
      "Epoch 26/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.2360 - acc: 0.2081\n",
      "Epoch 27/100\n",
      "620/620 [==============================] - 0s 169us/step - loss: 2.2533 - acc: 0.1774\n",
      "Epoch 28/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.3211 - acc: 0.1597\n",
      "Epoch 29/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.2654 - acc: 0.1806\n",
      "Epoch 30/100\n",
      "620/620 [==============================] - 0s 105us/step - loss: 2.2865 - acc: 0.1790\n",
      "Epoch 31/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.3284 - acc: 0.1919\n",
      "Epoch 32/100\n",
      "620/620 [==============================] - 0s 131us/step - loss: 2.2626 - acc: 0.1758\n",
      "Epoch 33/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.2714 - acc: 0.1919\n",
      "Epoch 34/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.2820 - acc: 0.1903\n",
      "Epoch 35/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.2222 - acc: 0.1903\n",
      "Epoch 36/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.3302 - acc: 0.1532\n",
      "Epoch 37/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.2557 - acc: 0.1629\n",
      "Epoch 38/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.2722 - acc: 0.1597\n",
      "Epoch 39/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.2874 - acc: 0.1661\n",
      "Epoch 40/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.2304 - acc: 0.1823\n",
      "Epoch 41/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.3327 - acc: 0.1548\n",
      "Epoch 42/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.3013 - acc: 0.1694\n",
      "Epoch 43/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.2692 - acc: 0.1903\n",
      "Epoch 44/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.3270 - acc: 0.1726\n",
      "Epoch 45/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.3052 - acc: 0.1774\n",
      "Epoch 46/100\n",
      "620/620 [==============================] - 0s 148us/step - loss: 2.3233 - acc: 0.1645\n",
      "Epoch 47/100\n",
      "620/620 [==============================] - 0s 137us/step - loss: 2.2562 - acc: 0.1661\n",
      "Epoch 48/100\n",
      "620/620 [==============================] - 0s 137us/step - loss: 2.2549 - acc: 0.1742\n",
      "Epoch 49/100\n",
      "620/620 [==============================] - 0s 131us/step - loss: 2.2911 - acc: 0.1823\n",
      "Epoch 50/100\n",
      "620/620 [==============================] - 0s 132us/step - loss: 2.2974 - acc: 0.1581\n",
      "Epoch 51/100\n",
      "620/620 [==============================] - 0s 129us/step - loss: 2.2602 - acc: 0.1774\n",
      "Epoch 52/100\n",
      "620/620 [==============================] - 0s 135us/step - loss: 2.3071 - acc: 0.1677\n",
      "Epoch 53/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.2965 - acc: 0.1661\n",
      "Epoch 54/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.2807 - acc: 0.1726\n",
      "Epoch 55/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.3080 - acc: 0.1742\n",
      "Epoch 56/100\n",
      "620/620 [==============================] - 0s 137us/step - loss: 2.2958 - acc: 0.1694\n",
      "Epoch 57/100\n",
      "620/620 [==============================] - 0s 129us/step - loss: 2.2652 - acc: 0.1726\n",
      "Epoch 58/100\n",
      "620/620 [==============================] - 0s 161us/step - loss: 2.2429 - acc: 0.1774\n",
      "Epoch 59/100\n",
      "620/620 [==============================] - 0s 147us/step - loss: 2.2382 - acc: 0.1645\n",
      "Epoch 60/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.3442 - acc: 0.1774\n",
      "Epoch 61/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.3177 - acc: 0.1790\n",
      "Epoch 62/100\n",
      "620/620 [==============================] - ETA: 0s - loss: 2.2996 - acc: 0.150 - 0s 127us/step - loss: 2.3219 - acc: 0.1484\n",
      "Epoch 63/100\n",
      "620/620 [==============================] - 0s 150us/step - loss: 2.2897 - acc: 0.1613\n",
      "Epoch 64/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.2551 - acc: 0.1629\n",
      "Epoch 65/100\n",
      "620/620 [==============================] - 0s 137us/step - loss: 2.2831 - acc: 0.1645\n",
      "Epoch 66/100\n",
      "620/620 [==============================] - 0s 144us/step - loss: 2.2968 - acc: 0.1597\n",
      "Epoch 67/100\n",
      "620/620 [==============================] - 0s 160us/step - loss: 2.2623 - acc: 0.1613\n",
      "Epoch 68/100\n",
      "620/620 [==============================] - 0s 150us/step - loss: 2.2491 - acc: 0.1742\n",
      "Epoch 69/100\n",
      "620/620 [==============================] - 0s 131us/step - loss: 2.2689 - acc: 0.1710\n",
      "Epoch 70/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.2571 - acc: 0.1790\n",
      "Epoch 71/100\n",
      "620/620 [==============================] - 0s 129us/step - loss: 2.2803 - acc: 0.1677\n",
      "Epoch 72/100\n",
      "620/620 [==============================] - 0s 129us/step - loss: 2.2518 - acc: 0.1790\n",
      "Epoch 73/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.3341 - acc: 0.1677\n",
      "Epoch 74/100\n",
      "620/620 [==============================] - 0s 121us/step - loss: 2.2407 - acc: 0.1952\n",
      "Epoch 75/100\n",
      "620/620 [==============================] - 0s 147us/step - loss: 2.2453 - acc: 0.1694\n",
      "Epoch 76/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.2848 - acc: 0.1710\n",
      "Epoch 77/100\n",
      "620/620 [==============================] - 0s 135us/step - loss: 2.2814 - acc: 0.1935\n",
      "Epoch 78/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.3118 - acc: 0.1677\n",
      "Epoch 79/100\n",
      "620/620 [==============================] - 0s 129us/step - loss: 2.3134 - acc: 0.1581\n",
      "Epoch 80/100\n",
      "620/620 [==============================] - 0s 139us/step - loss: 2.2679 - acc: 0.1629\n",
      "Epoch 81/100\n",
      "620/620 [==============================] - 0s 145us/step - loss: 2.2467 - acc: 0.1887\n",
      "Epoch 82/100\n",
      "620/620 [==============================] - 0s 187us/step - loss: 2.2698 - acc: 0.1903\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/620 [==============================] - 0s 165us/step - loss: 2.2921 - acc: 0.1774\n",
      "Epoch 84/100\n",
      "620/620 [==============================] - 0s 156us/step - loss: 2.2919 - acc: 0.1694\n",
      "Epoch 85/100\n",
      "620/620 [==============================] - 0s 142us/step - loss: 2.2874 - acc: 0.1565\n",
      "Epoch 86/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.2790 - acc: 0.1694\n",
      "Epoch 87/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.2750 - acc: 0.1597\n",
      "Epoch 88/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.2981 - acc: 0.1581\n",
      "Epoch 89/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.3115 - acc: 0.1597\n",
      "Epoch 90/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.3119 - acc: 0.1694\n",
      "Epoch 91/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.3475 - acc: 0.1581\n",
      "Epoch 92/100\n",
      "620/620 [==============================] - 0s 121us/step - loss: 2.2823 - acc: 0.1581\n",
      "Epoch 93/100\n",
      "620/620 [==============================] - ETA: 0s - loss: 2.3052 - acc: 0.150 - 0s 119us/step - loss: 2.3125 - acc: 0.1419\n",
      "Epoch 94/100\n",
      "620/620 [==============================] - 0s 150us/step - loss: 2.3251 - acc: 0.1694\n",
      "Epoch 95/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.2040 - acc: 0.1694\n",
      "Epoch 96/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.2768 - acc: 0.1806\n",
      "Epoch 97/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.2503 - acc: 0.1855\n",
      "Epoch 98/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.3157 - acc: 0.1548\n",
      "Epoch 99/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.2492 - acc: 0.1903\n",
      "Epoch 100/100\n",
      "620/620 [==============================] - 0s 121us/step - loss: 2.2877 - acc: 0.1677\n",
      "Epoch 1/100\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 2.3319 - acc: 0.1613\n",
      "Epoch 2/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.3020 - acc: 0.1919\n",
      "Epoch 3/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.3791 - acc: 0.1726\n",
      "Epoch 4/100\n",
      "620/620 [==============================] - 0s 129us/step - loss: 2.2697 - acc: 0.1742\n",
      "Epoch 5/100\n",
      "620/620 [==============================] - 0s 135us/step - loss: 2.3231 - acc: 0.1903\n",
      "Epoch 6/100\n",
      "620/620 [==============================] - 0s 147us/step - loss: 2.2858 - acc: 0.1806\n",
      "Epoch 7/100\n",
      "620/620 [==============================] - 0s 137us/step - loss: 2.2925 - acc: 0.1919\n",
      "Epoch 8/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.2738 - acc: 0.1710\n",
      "Epoch 9/100\n",
      "620/620 [==============================] - 0s 123us/step - loss: 2.3219 - acc: 0.1758\n",
      "Epoch 10/100\n",
      "620/620 [==============================] - 0s 114us/step - loss: 2.3090 - acc: 0.1613\n",
      "Epoch 11/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.3506 - acc: 0.1677\n",
      "Epoch 12/100\n",
      "620/620 [==============================] - 0s 121us/step - loss: 2.3012 - acc: 0.1871\n",
      "Epoch 13/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.2827 - acc: 0.1677\n",
      "Epoch 14/100\n",
      "620/620 [==============================] - 0s 121us/step - loss: 2.3246 - acc: 0.1581\n",
      "Epoch 15/100\n",
      "620/620 [==============================] - 0s 129us/step - loss: 2.3060 - acc: 0.1613\n",
      "Epoch 16/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.3315 - acc: 0.1790\n",
      "Epoch 17/100\n",
      "620/620 [==============================] - 0s 140us/step - loss: 2.3380 - acc: 0.1790\n",
      "Epoch 18/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.3328 - acc: 0.1661\n",
      "Epoch 19/100\n",
      "620/620 [==============================] - 0s 135us/step - loss: 2.2917 - acc: 0.1839\n",
      "Epoch 20/100\n",
      "620/620 [==============================] - 0s 152us/step - loss: 2.2717 - acc: 0.1871\n",
      "Epoch 21/100\n",
      "620/620 [==============================] - 0s 153us/step - loss: 2.2975 - acc: 0.1677\n",
      "Epoch 22/100\n",
      "620/620 [==============================] - 0s 147us/step - loss: 2.3421 - acc: 0.1726\n",
      "Epoch 23/100\n",
      "620/620 [==============================] - 0s 194us/step - loss: 2.3604 - acc: 0.1548\n",
      "Epoch 24/100\n",
      "620/620 [==============================] - 0s 132us/step - loss: 2.3490 - acc: 0.1645\n",
      "Epoch 25/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.4366 - acc: 0.1403\n",
      "Epoch 26/100\n",
      "620/620 [==============================] - 0s 129us/step - loss: 2.2885 - acc: 0.1774\n",
      "Epoch 27/100\n",
      "620/620 [==============================] - 0s 137us/step - loss: 2.3467 - acc: 0.1726\n",
      "Epoch 28/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.2815 - acc: 0.1823\n",
      "Epoch 29/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.3569 - acc: 0.1677\n",
      "Epoch 30/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.3403 - acc: 0.1758\n",
      "Epoch 31/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.3571 - acc: 0.1613\n",
      "Epoch 32/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.2888 - acc: 0.1742\n",
      "Epoch 33/100\n",
      "620/620 [==============================] - 0s 105us/step - loss: 2.3462 - acc: 0.1823\n",
      "Epoch 34/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.2794 - acc: 0.1823\n",
      "Epoch 35/100\n",
      "620/620 [==============================] - 0s 135us/step - loss: 2.3362 - acc: 0.1806\n",
      "Epoch 36/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.2977 - acc: 0.1694\n",
      "Epoch 37/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.3673 - acc: 0.1597\n",
      "Epoch 38/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.2799 - acc: 0.1774\n",
      "Epoch 39/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.3349 - acc: 0.1661\n",
      "Epoch 40/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.2946 - acc: 0.1855\n",
      "Epoch 41/100\n",
      "620/620 [==============================] - 0s 102us/step - loss: 2.2879 - acc: 0.1806\n",
      "Epoch 42/100\n",
      "620/620 [==============================] - 0s 98us/step - loss: 2.3006 - acc: 0.1806\n",
      "Epoch 43/100\n",
      "620/620 [==============================] - 0s 100us/step - loss: 2.3523 - acc: 0.1677\n",
      "Epoch 44/100\n",
      "620/620 [==============================] - 0s 100us/step - loss: 2.3181 - acc: 0.1726\n",
      "Epoch 45/100\n",
      "620/620 [==============================] - 0s 105us/step - loss: 2.3408 - acc: 0.1790\n",
      "Epoch 46/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.2643 - acc: 0.2032\n",
      "Epoch 47/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.3282 - acc: 0.1758\n",
      "Epoch 48/100\n",
      "620/620 [==============================] - 0s 105us/step - loss: 2.3260 - acc: 0.1935\n",
      "Epoch 49/100\n",
      "620/620 [==============================] - 0s 95us/step - loss: 2.3464 - acc: 0.1500\n",
      "Epoch 50/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.3396 - acc: 0.1661\n",
      "Epoch 51/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.3708 - acc: 0.1532\n",
      "Epoch 52/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.2819 - acc: 0.1839\n",
      "Epoch 53/100\n",
      "620/620 [==============================] - 0s 148us/step - loss: 2.3162 - acc: 0.1968\n",
      "Epoch 54/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.2920 - acc: 0.1758\n",
      "Epoch 55/100\n",
      "620/620 [==============================] - ETA: 0s - loss: 2.2998 - acc: 0.168 - 0s 124us/step - loss: 2.3561 - acc: 0.1500\n",
      "Epoch 56/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.2675 - acc: 0.1790\n",
      "Epoch 57/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.3325 - acc: 0.1500\n",
      "Epoch 58/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.2578 - acc: 0.1806\n",
      "Epoch 59/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.3323 - acc: 0.1774\n",
      "Epoch 60/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.3201 - acc: 0.1532\n",
      "Epoch 61/100\n",
      "620/620 [==============================] - 0s 139us/step - loss: 2.2914 - acc: 0.1790\n",
      "Epoch 62/100\n",
      "620/620 [==============================] - 0s 139us/step - loss: 2.2926 - acc: 0.1726\n",
      "Epoch 63/100\n",
      "620/620 [==============================] - 0s 123us/step - loss: 2.3060 - acc: 0.1806\n",
      "Epoch 64/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.3146 - acc: 0.1645\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/620 [==============================] - 0s 111us/step - loss: 2.3190 - acc: 0.1694\n",
      "Epoch 66/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.3201 - acc: 0.1565\n",
      "Epoch 67/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.3948 - acc: 0.1710\n",
      "Epoch 68/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.2905 - acc: 0.1806\n",
      "Epoch 69/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.2806 - acc: 0.1710\n",
      "Epoch 70/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.2694 - acc: 0.1758\n",
      "Epoch 71/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.3809 - acc: 0.1500\n",
      "Epoch 72/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.3184 - acc: 0.1629\n",
      "Epoch 73/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.3169 - acc: 0.1839\n",
      "Epoch 74/100\n",
      "620/620 [==============================] - 0s 131us/step - loss: 2.2676 - acc: 0.1710\n",
      "Epoch 75/100\n",
      "620/620 [==============================] - 0s 168us/step - loss: 2.3326 - acc: 0.1790\n",
      "Epoch 76/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.3406 - acc: 0.1694\n",
      "Epoch 77/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.3245 - acc: 0.1823\n",
      "Epoch 78/100\n",
      "620/620 [==============================] - 0s 139us/step - loss: 2.3798 - acc: 0.1694\n",
      "Epoch 79/100\n",
      "620/620 [==============================] - 0s 156us/step - loss: 2.3300 - acc: 0.1903\n",
      "Epoch 80/100\n",
      "620/620 [==============================] - 0s 153us/step - loss: 2.3116 - acc: 0.1952\n",
      "Epoch 81/100\n",
      "620/620 [==============================] - 0s 152us/step - loss: 2.2955 - acc: 0.1758\n",
      "Epoch 82/100\n",
      "620/620 [==============================] - 0s 145us/step - loss: 2.3407 - acc: 0.1839\n",
      "Epoch 83/100\n",
      "620/620 [==============================] - 0s 150us/step - loss: 2.2318 - acc: 0.1903\n",
      "Epoch 84/100\n",
      "620/620 [==============================] - 0s 148us/step - loss: 2.3269 - acc: 0.1774\n",
      "Epoch 85/100\n",
      "620/620 [==============================] - 0s 144us/step - loss: 2.3517 - acc: 0.1839\n",
      "Epoch 86/100\n",
      "620/620 [==============================] - 0s 142us/step - loss: 2.3291 - acc: 0.1952\n",
      "Epoch 87/100\n",
      "620/620 [==============================] - 0s 140us/step - loss: 2.3387 - acc: 0.1774\n",
      "Epoch 88/100\n",
      "620/620 [==============================] - 0s 168us/step - loss: 2.3395 - acc: 0.1871\n",
      "Epoch 89/100\n",
      "620/620 [==============================] - 0s 156us/step - loss: 2.3646 - acc: 0.1710\n",
      "Epoch 90/100\n",
      "620/620 [==============================] - 0s 142us/step - loss: 2.2816 - acc: 0.1710\n",
      "Epoch 91/100\n",
      "620/620 [==============================] - 0s 142us/step - loss: 2.3604 - acc: 0.1710\n",
      "Epoch 92/100\n",
      "620/620 [==============================] - 0s 148us/step - loss: 2.2975 - acc: 0.1613\n",
      "Epoch 93/100\n",
      "620/620 [==============================] - 0s 145us/step - loss: 2.3359 - acc: 0.1548\n",
      "Epoch 94/100\n",
      "620/620 [==============================] - 0s 140us/step - loss: 2.3077 - acc: 0.1903\n",
      "Epoch 95/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.3428 - acc: 0.1581\n",
      "Epoch 96/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.3781 - acc: 0.1710\n",
      "Epoch 97/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.3811 - acc: 0.1645\n",
      "Epoch 98/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.2945 - acc: 0.1806\n",
      "Epoch 99/100\n",
      "620/620 [==============================] - 0s 114us/step - loss: 2.3040 - acc: 0.1790\n",
      "Epoch 100/100\n",
      "620/620 [==============================] - 0s 123us/step - loss: 2.3120 - acc: 0.1565\n",
      "Epoch 1/100\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 2.5583 - acc: 0.1839\n",
      "Epoch 2/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.5047 - acc: 0.1710\n",
      "Epoch 3/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.5586 - acc: 0.1694\n",
      "Epoch 4/100\n",
      "620/620 [==============================] - 0s 148us/step - loss: 2.5502 - acc: 0.1710\n",
      "Epoch 5/100\n",
      "620/620 [==============================] - 0s 194us/step - loss: 2.5722 - acc: 0.1629\n",
      "Epoch 6/100\n",
      "620/620 [==============================] - 0s 163us/step - loss: 2.5068 - acc: 0.1968\n",
      "Epoch 7/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.5156 - acc: 0.1952\n",
      "Epoch 8/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.5998 - acc: 0.1629\n",
      "Epoch 9/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.5722 - acc: 0.1823\n",
      "Epoch 10/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.5363 - acc: 0.1806\n",
      "Epoch 11/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.4992 - acc: 0.1823\n",
      "Epoch 12/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.5854 - acc: 0.1774\n",
      "Epoch 13/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.5219 - acc: 0.1726\n",
      "Epoch 14/100\n",
      "620/620 [==============================] - 0s 131us/step - loss: 2.5633 - acc: 0.1919\n",
      "Epoch 15/100\n",
      "620/620 [==============================] - 0s 129us/step - loss: 2.5954 - acc: 0.1742\n",
      "Epoch 16/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.5207 - acc: 0.1645\n",
      "Epoch 17/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.5355 - acc: 0.1952\n",
      "Epoch 18/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.5171 - acc: 0.1790\n",
      "Epoch 19/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.5821 - acc: 0.1790\n",
      "Epoch 20/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.5230 - acc: 0.1919\n",
      "Epoch 21/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.6246 - acc: 0.1661\n",
      "Epoch 22/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.5319 - acc: 0.1694\n",
      "Epoch 23/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.6358 - acc: 0.1613\n",
      "Epoch 24/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.6230 - acc: 0.1645\n",
      "Epoch 25/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.6061 - acc: 0.1839\n",
      "Epoch 26/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.6078 - acc: 0.1790\n",
      "Epoch 27/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.5579 - acc: 0.1887\n",
      "Epoch 28/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.5583 - acc: 0.1839\n",
      "Epoch 29/100\n",
      "620/620 [==============================] - 0s 123us/step - loss: 2.5387 - acc: 0.1758\n",
      "Epoch 30/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.5427 - acc: 0.1968\n",
      "Epoch 31/100\n",
      "620/620 [==============================] - 0s 148us/step - loss: 2.5031 - acc: 0.1645\n",
      "Epoch 32/100\n",
      "620/620 [==============================] - 0s 202us/step - loss: 2.5798 - acc: 0.1726\n",
      "Epoch 33/100\n",
      "620/620 [==============================] - 0s 168us/step - loss: 2.5262 - acc: 0.1919\n",
      "Epoch 34/100\n",
      "620/620 [==============================] - 0s 174us/step - loss: 2.5361 - acc: 0.1806\n",
      "Epoch 35/100\n",
      "620/620 [==============================] - 0s 175us/step - loss: 2.5591 - acc: 0.1629\n",
      "Epoch 36/100\n",
      "620/620 [==============================] - 0s 167us/step - loss: 2.5280 - acc: 0.1661\n",
      "Epoch 37/100\n",
      "620/620 [==============================] - 0s 131us/step - loss: 2.5107 - acc: 0.2000\n",
      "Epoch 38/100\n",
      "620/620 [==============================] - 0s 153us/step - loss: 2.5621 - acc: 0.1774\n",
      "Epoch 39/100\n",
      "620/620 [==============================] - 0s 158us/step - loss: 2.5062 - acc: 0.1742\n",
      "Epoch 40/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.5402 - acc: 0.1887\n",
      "Epoch 41/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.6250 - acc: 0.1694\n",
      "Epoch 42/100\n",
      "620/620 [==============================] - 0s 163us/step - loss: 2.4940 - acc: 0.1968\n",
      "Epoch 43/100\n",
      "620/620 [==============================] - 0s 168us/step - loss: 2.5802 - acc: 0.1806\n",
      "Epoch 44/100\n",
      "620/620 [==============================] - 0s 195us/step - loss: 2.5036 - acc: 0.1903\n",
      "Epoch 45/100\n",
      "620/620 [==============================] - 0s 191us/step - loss: 2.5350 - acc: 0.1919\n",
      "Epoch 46/100\n",
      "620/620 [==============================] - 0s 156us/step - loss: 2.5465 - acc: 0.1694\n",
      "Epoch 47/100\n",
      "620/620 [==============================] - 0s 137us/step - loss: 2.5489 - acc: 0.1629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "620/620 [==============================] - 0s 123us/step - loss: 2.5693 - acc: 0.1565\n",
      "Epoch 49/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.5008 - acc: 0.1952\n",
      "Epoch 50/100\n",
      "620/620 [==============================] - 0s 181us/step - loss: 2.5619 - acc: 0.1806\n",
      "Epoch 51/100\n",
      "620/620 [==============================] - 0s 276us/step - loss: 2.5685 - acc: 0.1806\n",
      "Epoch 52/100\n",
      "620/620 [==============================] - 0s 182us/step - loss: 2.5066 - acc: 0.1903\n",
      "Epoch 53/100\n",
      "620/620 [==============================] - 0s 223us/step - loss: 2.5634 - acc: 0.1694\n",
      "Epoch 54/100\n",
      "620/620 [==============================] - 0s 163us/step - loss: 2.5426 - acc: 0.1855\n",
      "Epoch 55/100\n",
      "620/620 [==============================] - 0s 176us/step - loss: 2.5595 - acc: 0.1774\n",
      "Epoch 56/100\n",
      "620/620 [==============================] - 0s 169us/step - loss: 2.5068 - acc: 0.1710\n",
      "Epoch 57/100\n",
      "620/620 [==============================] - 0s 165us/step - loss: 2.5221 - acc: 0.1645\n",
      "Epoch 58/100\n",
      "620/620 [==============================] - 0s 248us/step - loss: 2.5024 - acc: 0.1935\n",
      "Epoch 59/100\n",
      "620/620 [==============================] - 0s 185us/step - loss: 2.5683 - acc: 0.1597\n",
      "Epoch 60/100\n",
      "620/620 [==============================] - 0s 158us/step - loss: 2.5976 - acc: 0.1677\n",
      "Epoch 61/100\n",
      "620/620 [==============================] - 0s 160us/step - loss: 2.5728 - acc: 0.1919\n",
      "Epoch 62/100\n",
      "620/620 [==============================] - 0s 160us/step - loss: 2.5201 - acc: 0.1903\n",
      "Epoch 63/100\n",
      "620/620 [==============================] - 0s 226us/step - loss: 2.5138 - acc: 0.1903\n",
      "Epoch 64/100\n",
      "620/620 [==============================] - 0s 192us/step - loss: 2.5484 - acc: 0.1726\n",
      "Epoch 65/100\n",
      "620/620 [==============================] - 0s 216us/step - loss: 2.5811 - acc: 0.1806\n",
      "Epoch 66/100\n",
      "620/620 [==============================] - 0s 153us/step - loss: 2.5359 - acc: 0.1806\n",
      "Epoch 67/100\n",
      "620/620 [==============================] - 0s 153us/step - loss: 2.5627 - acc: 0.1806\n",
      "Epoch 68/100\n",
      "620/620 [==============================] - 0s 240us/step - loss: 2.5254 - acc: 0.1903\n",
      "Epoch 69/100\n",
      "620/620 [==============================] - 0s 245us/step - loss: 2.5359 - acc: 0.1581\n",
      "Epoch 70/100\n",
      "620/620 [==============================] - 0s 171us/step - loss: 2.5508 - acc: 0.1677\n",
      "Epoch 71/100\n",
      "620/620 [==============================] - 0s 162us/step - loss: 2.5681 - acc: 0.1645\n",
      "Epoch 72/100\n",
      "620/620 [==============================] - 0s 203us/step - loss: 2.5167 - acc: 0.1677\n",
      "Epoch 73/100\n",
      "620/620 [==============================] - 0s 231us/step - loss: 2.5405 - acc: 0.1935\n",
      "Epoch 74/100\n",
      "620/620 [==============================] - 0s 163us/step - loss: 2.5316 - acc: 0.1855\n",
      "Epoch 75/100\n",
      "620/620 [==============================] - 0s 150us/step - loss: 2.5913 - acc: 0.1629\n",
      "Epoch 76/100\n",
      "620/620 [==============================] - 0s 139us/step - loss: 2.5111 - acc: 0.1452\n",
      "Epoch 77/100\n",
      "620/620 [==============================] - 0s 144us/step - loss: 2.5594 - acc: 0.1871\n",
      "Epoch 78/100\n",
      "620/620 [==============================] - 0s 142us/step - loss: 2.5580 - acc: 0.1871\n",
      "Epoch 79/100\n",
      "620/620 [==============================] - 0s 142us/step - loss: 2.5655 - acc: 0.1968\n",
      "Epoch 80/100\n",
      "620/620 [==============================] - 0s 147us/step - loss: 2.5757 - acc: 0.1871\n",
      "Epoch 81/100\n",
      "620/620 [==============================] - 0s 145us/step - loss: 2.5765 - acc: 0.1677\n",
      "Epoch 82/100\n",
      "620/620 [==============================] - 0s 139us/step - loss: 2.5642 - acc: 0.1742\n",
      "Epoch 83/100\n",
      "620/620 [==============================] - 0s 121us/step - loss: 2.5219 - acc: 0.1871\n",
      "Epoch 84/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.5607 - acc: 0.1661\n",
      "Epoch 85/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.5141 - acc: 0.1855\n",
      "Epoch 86/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.5673 - acc: 0.1774\n",
      "Epoch 87/100\n",
      "620/620 [==============================] - 0s 121us/step - loss: 2.4906 - acc: 0.1935\n",
      "Epoch 88/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.6038 - acc: 0.1565\n",
      "Epoch 89/100\n",
      "620/620 [==============================] - 0s 147us/step - loss: 2.5392 - acc: 0.1887\n",
      "Epoch 90/100\n",
      "620/620 [==============================] - 0s 142us/step - loss: 2.5415 - acc: 0.1903\n",
      "Epoch 91/100\n",
      "620/620 [==============================] - 0s 142us/step - loss: 2.5209 - acc: 0.1855\n",
      "Epoch 92/100\n",
      "620/620 [==============================] - 0s 135us/step - loss: 2.5669 - acc: 0.1742\n",
      "Epoch 93/100\n",
      "620/620 [==============================] - 0s 148us/step - loss: 2.5519 - acc: 0.1855\n",
      "Epoch 94/100\n",
      "620/620 [==============================] - 0s 135us/step - loss: 2.5057 - acc: 0.1597\n",
      "Epoch 95/100\n",
      "620/620 [==============================] - 0s 135us/step - loss: 2.6181 - acc: 0.1710\n",
      "Epoch 96/100\n",
      "620/620 [==============================] - 0s 147us/step - loss: 2.5318 - acc: 0.1532\n",
      "Epoch 97/100\n",
      "620/620 [==============================] - 0s 156us/step - loss: 2.5865 - acc: 0.1774\n",
      "Epoch 98/100\n",
      "620/620 [==============================] - 0s 158us/step - loss: 2.5428 - acc: 0.1823\n",
      "Epoch 99/100\n",
      "620/620 [==============================] - 0s 153us/step - loss: 2.5579 - acc: 0.1903\n",
      "Epoch 100/100\n",
      "620/620 [==============================] - 0s 161us/step - loss: 2.5838 - acc: 0.1790\n",
      "Epoch 1/100\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 2.1972 - acc: 0.1823\n",
      "Epoch 2/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.1946 - acc: 0.2065\n",
      "Epoch 3/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.2037 - acc: 0.1855\n",
      "Epoch 4/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.1841 - acc: 0.1871\n",
      "Epoch 5/100\n",
      "620/620 [==============================] - 0s 100us/step - loss: 2.1891 - acc: 0.1839\n",
      "Epoch 6/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.1309 - acc: 0.1935\n",
      "Epoch 7/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.1759 - acc: 0.1710\n",
      "Epoch 8/100\n",
      "620/620 [==============================] - 0s 102us/step - loss: 2.1572 - acc: 0.1645\n",
      "Epoch 9/100\n",
      "620/620 [==============================] - 0s 103us/step - loss: 2.1473 - acc: 0.2016\n",
      "Epoch 10/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.1910 - acc: 0.1935\n",
      "Epoch 11/100\n",
      "620/620 [==============================] - 0s 100us/step - loss: 2.2401 - acc: 0.1919\n",
      "Epoch 12/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.2205 - acc: 0.1968\n",
      "Epoch 13/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.2133 - acc: 0.1774\n",
      "Epoch 14/100\n",
      "620/620 [==============================] - 0s 135us/step - loss: 2.2000 - acc: 0.1758\n",
      "Epoch 15/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.1768 - acc: 0.1952\n",
      "Epoch 16/100\n",
      "620/620 [==============================] - 0s 152us/step - loss: 2.1151 - acc: 0.2000\n",
      "Epoch 17/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1619 - acc: 0.1855\n",
      "Epoch 18/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1585 - acc: 0.1629\n",
      "Epoch 19/100\n",
      "620/620 [==============================] - 0s 98us/step - loss: 2.1887 - acc: 0.1790\n",
      "Epoch 20/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.1265 - acc: 0.2242\n",
      "Epoch 21/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.1768 - acc: 0.1726\n",
      "Epoch 22/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.1870 - acc: 0.2016\n",
      "Epoch 23/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.1413 - acc: 0.1677\n",
      "Epoch 24/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1490 - acc: 0.1774\n",
      "Epoch 25/100\n",
      "620/620 [==============================] - 0s 95us/step - loss: 2.1505 - acc: 0.2113\n",
      "Epoch 26/100\n",
      "620/620 [==============================] - 0s 103us/step - loss: 2.1822 - acc: 0.2016\n",
      "Epoch 27/100\n",
      "620/620 [==============================] - 0s 103us/step - loss: 2.1788 - acc: 0.1887\n",
      "Epoch 28/100\n",
      "620/620 [==============================] - 0s 102us/step - loss: 2.1280 - acc: 0.2210\n",
      "Epoch 29/100\n",
      "620/620 [==============================] - 0s 100us/step - loss: 2.1911 - acc: 0.1919\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/620 [==============================] - 0s 108us/step - loss: 2.1327 - acc: 0.2161\n",
      "Epoch 31/100\n",
      "620/620 [==============================] - 0s 98us/step - loss: 2.1743 - acc: 0.1855\n",
      "Epoch 32/100\n",
      "620/620 [==============================] - 0s 105us/step - loss: 2.2341 - acc: 0.1694\n",
      "Epoch 33/100\n",
      "620/620 [==============================] - 0s 98us/step - loss: 2.1365 - acc: 0.2194\n",
      "Epoch 34/100\n",
      "620/620 [==============================] - 0s 100us/step - loss: 2.1825 - acc: 0.1855\n",
      "Epoch 35/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.1781 - acc: 0.2081\n",
      "Epoch 36/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.2152 - acc: 0.1758\n",
      "Epoch 37/100\n",
      "620/620 [==============================] - 0s 152us/step - loss: 2.1299 - acc: 0.1823\n",
      "Epoch 38/100\n",
      "620/620 [==============================] - 0s 145us/step - loss: 2.1810 - acc: 0.1710\n",
      "Epoch 39/100\n",
      "620/620 [==============================] - 0s 142us/step - loss: 2.1521 - acc: 0.2081\n",
      "Epoch 40/100\n",
      "620/620 [==============================] - 0s 139us/step - loss: 2.2190 - acc: 0.1871\n",
      "Epoch 41/100\n",
      "620/620 [==============================] - 0s 100us/step - loss: 2.2270 - acc: 0.1694\n",
      "Epoch 42/100\n",
      "620/620 [==============================] - 0s 98us/step - loss: 2.1366 - acc: 0.1919\n",
      "Epoch 43/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.1574 - acc: 0.2226\n",
      "Epoch 44/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.1784 - acc: 0.1871\n",
      "Epoch 45/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.1199 - acc: 0.1968\n",
      "Epoch 46/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1863 - acc: 0.1919\n",
      "Epoch 47/100\n",
      "620/620 [==============================] - 0s 97us/step - loss: 2.1488 - acc: 0.2016\n",
      "Epoch 48/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.1665 - acc: 0.1742\n",
      "Epoch 49/100\n",
      "620/620 [==============================] - 0s 102us/step - loss: 2.2128 - acc: 0.1855\n",
      "Epoch 50/100\n",
      "620/620 [==============================] - 0s 97us/step - loss: 2.1818 - acc: 0.1742\n",
      "Epoch 51/100\n",
      "620/620 [==============================] - 0s 102us/step - loss: 2.2357 - acc: 0.1839\n",
      "Epoch 52/100\n",
      "620/620 [==============================] - 0s 139us/step - loss: 2.2039 - acc: 0.1823\n",
      "Epoch 53/100\n",
      "620/620 [==============================] - 0s 139us/step - loss: 2.2065 - acc: 0.1871\n",
      "Epoch 54/100\n",
      "620/620 [==============================] - 0s 139us/step - loss: 2.1649 - acc: 0.1726\n",
      "Epoch 55/100\n",
      "620/620 [==============================] - 0s 137us/step - loss: 2.1756 - acc: 0.2177\n",
      "Epoch 56/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.1760 - acc: 0.2081\n",
      "Epoch 57/100\n",
      "620/620 [==============================] - 0s 129us/step - loss: 2.2095 - acc: 0.2016\n",
      "Epoch 58/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.1584 - acc: 0.2048\n",
      "Epoch 59/100\n",
      "620/620 [==============================] - 0s 132us/step - loss: 2.1324 - acc: 0.1903\n",
      "Epoch 60/100\n",
      "620/620 [==============================] - 0s 137us/step - loss: 2.1789 - acc: 0.1839\n",
      "Epoch 61/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.1185 - acc: 0.2081\n",
      "Epoch 62/100\n",
      "620/620 [==============================] - 0s 135us/step - loss: 2.1682 - acc: 0.2065\n",
      "Epoch 63/100\n",
      "620/620 [==============================] - 0s 131us/step - loss: 2.1812 - acc: 0.1935\n",
      "Epoch 64/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.1927 - acc: 0.1919\n",
      "Epoch 65/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.1754 - acc: 0.2081\n",
      "Epoch 66/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.1429 - acc: 0.2032\n",
      "Epoch 67/100\n",
      "620/620 [==============================] - 0s 131us/step - loss: 2.1871 - acc: 0.1532\n",
      "Epoch 68/100\n",
      "620/620 [==============================] - 0s 132us/step - loss: 2.1742 - acc: 0.1774\n",
      "Epoch 69/100\n",
      "620/620 [==============================] - 0s 129us/step - loss: 2.1788 - acc: 0.2032\n",
      "Epoch 70/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.1693 - acc: 0.1790\n",
      "Epoch 71/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.1661 - acc: 0.1935\n",
      "Epoch 72/100\n",
      "620/620 [==============================] - 0s 129us/step - loss: 2.1751 - acc: 0.2032\n",
      "Epoch 73/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.1578 - acc: 0.1952\n",
      "Epoch 74/100\n",
      "620/620 [==============================] - 0s 131us/step - loss: 2.1938 - acc: 0.1919\n",
      "Epoch 75/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.2374 - acc: 0.1984\n",
      "Epoch 76/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.1980 - acc: 0.1919\n",
      "Epoch 77/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.2112 - acc: 0.1806\n",
      "Epoch 78/100\n",
      "620/620 [==============================] - 0s 121us/step - loss: 2.1969 - acc: 0.1790\n",
      "Epoch 79/100\n",
      "620/620 [==============================] - 0s 100us/step - loss: 2.1546 - acc: 0.2016\n",
      "Epoch 80/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.1804 - acc: 0.1952\n",
      "Epoch 81/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.1440 - acc: 0.1742\n",
      "Epoch 82/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.2303 - acc: 0.1581\n",
      "Epoch 83/100\n",
      "620/620 [==============================] - 0s 121us/step - loss: 2.1552 - acc: 0.1952\n",
      "Epoch 84/100\n",
      "620/620 [==============================] - 0s 98us/step - loss: 2.2033 - acc: 0.1710\n",
      "Epoch 85/100\n",
      "620/620 [==============================] - 0s 114us/step - loss: 2.1556 - acc: 0.1984\n",
      "Epoch 86/100\n",
      "620/620 [==============================] - 0s 100us/step - loss: 2.1702 - acc: 0.1984\n",
      "Epoch 87/100\n",
      "620/620 [==============================] - 0s 231us/step - loss: 2.1835 - acc: 0.2048\n",
      "Epoch 88/100\n",
      "620/620 [==============================] - 0s 123us/step - loss: 2.1517 - acc: 0.2032\n",
      "Epoch 89/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1666 - acc: 0.1823\n",
      "Epoch 90/100\n",
      "620/620 [==============================] - 0s 105us/step - loss: 2.1732 - acc: 0.1919\n",
      "Epoch 91/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.1668 - acc: 0.1984\n",
      "Epoch 92/100\n",
      "620/620 [==============================] - 0s 102us/step - loss: 2.1045 - acc: 0.2161\n",
      "Epoch 93/100\n",
      "620/620 [==============================] - 0s 134us/step - loss: 2.2352 - acc: 0.1806\n",
      "Epoch 94/100\n",
      "620/620 [==============================] - 0s 177us/step - loss: 2.1952 - acc: 0.1694\n",
      "Epoch 95/100\n",
      "620/620 [==============================] - 0s 152us/step - loss: 2.1800 - acc: 0.1903\n",
      "Epoch 96/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.1592 - acc: 0.2000\n",
      "Epoch 97/100\n",
      "620/620 [==============================] - 0s 131us/step - loss: 2.1544 - acc: 0.1919\n",
      "Epoch 98/100\n",
      "620/620 [==============================] - 0s 132us/step - loss: 2.1701 - acc: 0.1887\n",
      "Epoch 99/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.1790 - acc: 0.2129\n",
      "Epoch 100/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.1934 - acc: 0.1806\n",
      "Epoch 1/100\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 2.1881 - acc: 0.1855\n",
      "Epoch 2/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.1924 - acc: 0.1758\n",
      "Epoch 3/100\n",
      "620/620 [==============================] - 0s 132us/step - loss: 2.1657 - acc: 0.1710\n",
      "Epoch 4/100\n",
      "620/620 [==============================] - 0s 137us/step - loss: 2.1348 - acc: 0.1952\n",
      "Epoch 5/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.1251 - acc: 0.2097\n",
      "Epoch 6/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.1275 - acc: 0.1742\n",
      "Epoch 7/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.1126 - acc: 0.1742\n",
      "Epoch 8/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.1893 - acc: 0.1645\n",
      "Epoch 9/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1329 - acc: 0.1839\n",
      "Epoch 10/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1211 - acc: 0.2032\n",
      "Epoch 11/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.1117 - acc: 0.1903\n",
      "Epoch 12/100\n",
      "620/620 [==============================] - 0s 102us/step - loss: 2.1794 - acc: 0.1855\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/620 [==============================] - 0s 111us/step - loss: 2.1758 - acc: 0.1645\n",
      "Epoch 14/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.1327 - acc: 0.1935\n",
      "Epoch 15/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.1646 - acc: 0.1790\n",
      "Epoch 16/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.1502 - acc: 0.1871\n",
      "Epoch 17/100\n",
      "620/620 [==============================] - 0s 137us/step - loss: 2.1638 - acc: 0.1903\n",
      "Epoch 18/100\n",
      "620/620 [==============================] - 0s 137us/step - loss: 2.1587 - acc: 0.1935\n",
      "Epoch 19/100\n",
      "620/620 [==============================] - 0s 132us/step - loss: 2.1353 - acc: 0.1742\n",
      "Epoch 20/100\n",
      "620/620 [==============================] - 0s 135us/step - loss: 2.1400 - acc: 0.1903\n",
      "Epoch 21/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.1421 - acc: 0.1935\n",
      "Epoch 22/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1178 - acc: 0.1758\n",
      "Epoch 23/100\n",
      "620/620 [==============================] - 0s 103us/step - loss: 2.1327 - acc: 0.1774\n",
      "Epoch 24/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.1935 - acc: 0.1984\n",
      "Epoch 25/100\n",
      "620/620 [==============================] - 0s 142us/step - loss: 2.1671 - acc: 0.1871\n",
      "Epoch 26/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.1769 - acc: 0.1758\n",
      "Epoch 27/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.1122 - acc: 0.1694\n",
      "Epoch 28/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.1514 - acc: 0.1839\n",
      "Epoch 29/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.1550 - acc: 0.2097\n",
      "Epoch 30/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.1425 - acc: 0.2145\n",
      "Epoch 31/100\n",
      "620/620 [==============================] - 0s 105us/step - loss: 2.1811 - acc: 0.1806\n",
      "Epoch 32/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.1619 - acc: 0.1806\n",
      "Epoch 33/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1264 - acc: 0.1871\n",
      "Epoch 34/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.1793 - acc: 0.1823\n",
      "Epoch 35/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1473 - acc: 0.1968\n",
      "Epoch 36/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1513 - acc: 0.1710\n",
      "Epoch 37/100\n",
      "620/620 [==============================] - 0s 103us/step - loss: 2.1406 - acc: 0.1887\n",
      "Epoch 38/100\n",
      "620/620 [==============================] - 0s 103us/step - loss: 2.1583 - acc: 0.1710\n",
      "Epoch 39/100\n",
      "620/620 [==============================] - 0s 103us/step - loss: 2.1291 - acc: 0.1855\n",
      "Epoch 40/100\n",
      "620/620 [==============================] - 0s 121us/step - loss: 2.1269 - acc: 0.1952\n",
      "Epoch 41/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.1128 - acc: 0.1806\n",
      "Epoch 42/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.1597 - acc: 0.2081\n",
      "Epoch 43/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.0974 - acc: 0.2048\n",
      "Epoch 44/100\n",
      "620/620 [==============================] - 0s 124us/step - loss: 2.1639 - acc: 0.1919\n",
      "Epoch 45/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.1603 - acc: 0.1839\n",
      "Epoch 46/100\n",
      "620/620 [==============================] - 0s 131us/step - loss: 2.1290 - acc: 0.1935\n",
      "Epoch 47/100\n",
      "620/620 [==============================] - 0s 123us/step - loss: 2.1427 - acc: 0.1823\n",
      "Epoch 48/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.1874 - acc: 0.1806\n",
      "Epoch 49/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1237 - acc: 0.1823\n",
      "Epoch 50/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.1556 - acc: 0.1726\n",
      "Epoch 51/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.1350 - acc: 0.1806\n",
      "Epoch 52/100\n",
      "620/620 [==============================] - 0s 105us/step - loss: 2.1337 - acc: 0.1855\n",
      "Epoch 53/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.1723 - acc: 0.1790\n",
      "Epoch 54/100\n",
      "620/620 [==============================] - 0s 103us/step - loss: 2.1325 - acc: 0.1790\n",
      "Epoch 55/100\n",
      "620/620 [==============================] - 0s 103us/step - loss: 2.1514 - acc: 0.1839\n",
      "Epoch 56/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.1326 - acc: 0.1839\n",
      "Epoch 57/100\n",
      "620/620 [==============================] - 0s 137us/step - loss: 2.1274 - acc: 0.1694\n",
      "Epoch 58/100\n",
      "620/620 [==============================] - 0s 131us/step - loss: 2.1693 - acc: 0.1613\n",
      "Epoch 59/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.1054 - acc: 0.2032\n",
      "Epoch 60/100\n",
      "620/620 [==============================] - 0s 137us/step - loss: 2.1528 - acc: 0.1726\n",
      "Epoch 61/100\n",
      "620/620 [==============================] - 0s 118us/step - loss: 2.1123 - acc: 0.1887\n",
      "Epoch 62/100\n",
      "620/620 [==============================] - 0s 105us/step - loss: 2.1702 - acc: 0.1742\n",
      "Epoch 63/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1939 - acc: 0.1823\n",
      "Epoch 64/100\n",
      "620/620 [==============================] - 0s 103us/step - loss: 2.1559 - acc: 0.1774\n",
      "Epoch 65/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.1024 - acc: 0.1919\n",
      "Epoch 66/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1665 - acc: 0.1935\n",
      "Epoch 67/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.1664 - acc: 0.1790\n",
      "Epoch 68/100\n",
      "620/620 [==============================] - 0s 105us/step - loss: 2.1716 - acc: 0.1903\n",
      "Epoch 69/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.1457 - acc: 0.1903\n",
      "Epoch 70/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.1561 - acc: 0.1871\n",
      "Epoch 71/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.0895 - acc: 0.1952\n",
      "Epoch 72/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.1067 - acc: 0.1919\n",
      "Epoch 73/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.0861 - acc: 0.2145\n",
      "Epoch 74/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.1029 - acc: 0.1968\n",
      "Epoch 75/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.1314 - acc: 0.1742\n",
      "Epoch 76/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.1826 - acc: 0.1823\n",
      "Epoch 77/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.1964 - acc: 0.1871\n",
      "Epoch 78/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.1277 - acc: 0.1710\n",
      "Epoch 79/100\n",
      "620/620 [==============================] - 0s 103us/step - loss: 2.1813 - acc: 0.1839\n",
      "Epoch 80/100\n",
      "620/620 [==============================] - 0s 126us/step - loss: 2.1379 - acc: 0.1855\n",
      "Epoch 81/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.1648 - acc: 0.1871\n",
      "Epoch 82/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.1481 - acc: 0.1871\n",
      "Epoch 83/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.1280 - acc: 0.1935\n",
      "Epoch 84/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.1474 - acc: 0.1919\n",
      "Epoch 85/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.1116 - acc: 0.1887\n",
      "Epoch 86/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.1535 - acc: 0.1694\n",
      "Epoch 87/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.1046 - acc: 0.1952\n",
      "Epoch 88/100\n",
      "620/620 [==============================] - 0s 111us/step - loss: 2.1548 - acc: 0.1823\n",
      "Epoch 89/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.1365 - acc: 0.1823\n",
      "Epoch 90/100\n",
      "620/620 [==============================] - 0s 113us/step - loss: 2.0804 - acc: 0.2177\n",
      "Epoch 91/100\n",
      "620/620 [==============================] - 0s 127us/step - loss: 2.1045 - acc: 0.1952\n",
      "Epoch 92/100\n",
      "620/620 [==============================] - 0s 119us/step - loss: 2.1668 - acc: 0.1823\n",
      "Epoch 93/100\n",
      "620/620 [==============================] - 0s 116us/step - loss: 2.1470 - acc: 0.2081\n",
      "Epoch 94/100\n",
      "620/620 [==============================] - 0s 106us/step - loss: 2.1681 - acc: 0.1919\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/620 [==============================] - 0s 110us/step - loss: 2.0779 - acc: 0.2081\n",
      "Epoch 96/100\n",
      "620/620 [==============================] - 0s 102us/step - loss: 2.1727 - acc: 0.1903\n",
      "Epoch 97/100\n",
      "620/620 [==============================] - 0s 115us/step - loss: 2.1733 - acc: 0.1823\n",
      "Epoch 98/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.1841 - acc: 0.1855\n",
      "Epoch 99/100\n",
      "620/620 [==============================] - 0s 108us/step - loss: 2.1562 - acc: 0.1935\n",
      "Epoch 100/100\n",
      "620/620 [==============================] - 0s 110us/step - loss: 2.1202 - acc: 0.2032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('model1',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x000002476DA64FC8>),\n",
       "                             ('model2',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x000002476DA64F88>),\n",
       "                             ('model3',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x000002476E160888>),\n",
       "                             ('model4',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x000002476DA6D188>),\n",
       "                             ('model5',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x000002476DA6D088>)],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_clf.fit(x_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_predicted = ensemble_clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:  0.11129032258064517\n"
     ]
    }
   ],
   "source": [
    "print('Acc: ', accuracy_score(ytrain_predicted, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_predicted = ensemble_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, 2, 2, 2, 0, 1, 4, 3, 4, 1, 0, 1, 1, 4, 1, 3, 4, 2, 1, 0,\n",
       "       1, 1, 3, 3, 3, 3, 2, 0, 0, 0, 1, 0, 4, 0, 3, 1, 0, 1, 0, 2, 4, 4,\n",
       "       1, 3, 0, 0, 2, 2, 0, 2, 4, 0, 0, 4, 0, 2, 4, 1, 3, 1, 1, 2, 0, 0,\n",
       "       1, 0, 3, 0, 1, 0, 4, 0, 4, 4, 0, 0, 0, 3, 0, 3, 4, 4, 2, 3, 2, 3,\n",
       "       1, 3, 1, 4, 4, 0, 4, 1, 1, 2, 4, 4, 0, 4, 3, 3, 0, 3, 1, 2, 3, 4,\n",
       "       0, 0, 3, 1, 1, 0, 0, 0, 3, 0, 4, 1, 1, 1, 4, 4, 2, 3, 0, 1, 3, 1,\n",
       "       4, 0, 2, 0, 3, 1, 4, 1, 0, 0, 4, 3, 0, 1, 0, 3, 2, 0, 0, 0, 4, 1,\n",
       "       3, 0, 2, 0, 0, 0, 1, 1, 4, 2, 4, 0, 2, 1, 2, 0, 4, 4, 4, 0, 2, 1,\n",
       "       0, 0, 3, 4, 3, 3, 1, 1, 4, 4, 4, 4, 4, 4, 0, 2, 0, 3, 1, 1, 2, 0,\n",
       "       4, 0, 0, 1, 0, 4, 4, 4, 2, 1, 1, 4, 3, 0, 1, 2, 1, 0, 2, 2, 0, 1,\n",
       "       4, 1, 3, 1, 4, 0, 0, 0, 1, 4, 1, 0, 0, 1, 1, 3, 0, 2, 3, 1, 1, 4,\n",
       "       4, 2, 1, 2, 1, 3, 3, 1, 0, 1, 2, 4, 2, 4, 0, 3, 0, 3, 4, 4, 3, 4,\n",
       "       1, 3], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_array=to_categorical(ytest_predicted).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sub_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame(data=sub_array,  columns=[0, 1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel('adam.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
